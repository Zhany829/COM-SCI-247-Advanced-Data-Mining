{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS247 Advanced Data Mining - Assignment 1\n",
    "## Deadline: 11:59PM, January 24, 2023\n",
    "\n",
    "## Instructions\n",
    "Each assignment is structured as a Jupyter notebook, offering interactive tutorials that align with our lectures. You will encounter two types of problems: *write-up problems* and *coding problems*.\n",
    "\n",
    "1. **Write-up Problems:** These problems are primarily theoretical, requiring you to demonstrate your understanding of lecture concepts and to provide mathematical proofs for key theorems. Your answers should include sufficient steps for the mathematical derivations.\n",
    "2. **Coding Problems:** Here, you will be engaging with practical coding tasks. These may involve completing code segments provided in the notebooks or developing models from scratch.\n",
    "\n",
    "To ensure clarity and consistency in your submissions, please adhere to the following guidelines:\n",
    "\n",
    "* For write-up problems, use Markdown bullet points to format text answers. Also, express all mathematical equations using $\\LaTeX$ and avoid plain text such as `x0`, `x^1`, or `R x Q` for equations.\n",
    "* For coding problems, comment on your code thoroughly for readability and ensure your code is executable. Non-runnable code may lead to a loss of **all** points. Coding problems have automated grading, and altering the grading code will result in a deduction of **all** points.\n",
    "* Your submission should show the entire process of data loading, preprocessing, model implementation, training, and result analysis. This can be achieved through a mix of explanatory text cells, inline comments, intermediate result displays, and experimental visualizations.\n",
    "\n",
    "### Submission Requirements\n",
    "\n",
    "* Submit your solutions through GradeScope in BruinLearn.\n",
    "* Late submissions are allowed up to 24 hours post-deadline with a penalty factor of $\\mathbf{1}(t\\leq24)e^{-(\\ln(2)/12)t}$.\n",
    "\n",
    "### Collaboration and Integrity\n",
    "\n",
    "* Collaboration is encouraged, but all final submissions must be your own work. Please acknowledge any collaboration or external sources used, including websites, papers, and GitHub repositories.\n",
    "* Any suspicious cases of academic misconduct will be reported to The Office of the Dean of Students.\n",
    "\n",
    "## Outline\n",
    "* Problem 1: Naïve Bayes (50 points)\n",
    "* Problem 2: Logistic Regression (50 points)\n",
    "* Problem 3: Gaussian Mixture Models (70 points + 10 bonus points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Naïve Bayes (50 points) <a class=\"anchor\" id=\"problem-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1: MLE Estimation of Model Parameters (10 points)\n",
    "\n",
    "Recall that given a corpus and labels for each document $D = \\{(\\boldsymbol{x}_d, y_d)\\}_{d=1}^{|D|}$, the log likelihood function of a Bayes model parameterized by $\\Theta = (\\boldsymbol\\beta_1, \\boldsymbol\\beta_2, \\boldsymbol\\beta_3, \\boldsymbol\\pi)$ is:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{L}(\\Theta) & = \\log \\prod_{d=1}^{|D|} p(\\boldsymbol{x}_d, y_d | \\Theta) \\\\\n",
    "& = \\sum_{d=1}^{|D|} \\log p(\\boldsymbol{x}_d, y_d | \\Theta) \\\\\n",
    "& = \\sum_{d=1}^{|D|} \\log [p(\\boldsymbol{x}_d | y_d, \\Theta) p(y_d | \\Theta)] \\\\\n",
    "& = \\sum_{d=1}^{|D|} \\left(\\sum_{n=1}^{N}x_{dn}\\log\\beta_{y_d,n} + \\log \\pi_{y_d}\\right).\n",
    "\\end{align}\n",
    "$$\n",
    "Show the MLE estimator of $\\boldsymbol\\beta$. Include necessary derivatives in your answer. (Hint: use Lagrange multipliers to enforce the constraint $\\sum_{n=1}^{N}\\beta_{j,n} = 1$ for all $j$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TODO: Write your answer here]**\n",
    "To find the Maximum Likelihood Estimation estimator of $\\beta$, need to maximize the log-likelihood function $\\mathcal{L}(\\Theta)$ with respect to $\\boldsymbol\\beta$. The log-likelihood function is given by: \n",
    "$$\n",
    "\\mathcal{L}(\\Theta) = \\sum_{d=1}^{|D|} \\left(\\sum_{n=1}^{N}x_{dn}\\log\\beta_{y_d,n} + \\log \\pi_{y_d}\\right).\n",
    "$$\n",
    "To maximize $\\mathcal{L}(\\Theta)$, we can maximize each term separately. Let's consider a single term of the log-likelihood function:\n",
    "$$\n",
    "\\mathcal{L}_d(\\beta) = \\sum_{n=1}^{N} x_{dn}\\log\\beta_{y_d,n} + \\log \\pi_{y_d}).\n",
    "$$\n",
    "let's introduce the constraint $\\sum_{n=1}^{N}\\beta_{j,n} = 1$ for all $j$, using Lagrange multipliers. We define the Lagrangian function as:\n",
    "$$\n",
    "\\mathcal{J}_d(\\beta,\\lambda) = \\mathcal{L}_d(\\beta) + \\lambda (\\sum_{n=1}^{N} \\beta_{j,n}-1).\n",
    "$$\n",
    "To find the MLE estimator, we need to find the values of $\\boldsymbol\\beta$ that maximize $\\mathcal{J}_d(\\boldsymbol\\beta, \\lambda)$. We can start by finding the partial derivatives of $\\mathcal{J}d(\\boldsymbol\\beta, \\lambda)$ with respect to $\\beta{j,n}$ and $\\lambda$ and set them to zero.\n",
    "Taking the derivative with respect to $\\beta_{j,n}$:\n",
    "$$\n",
    "\\frac{\\bigtriangledown \\mathcal{J}_d(\\beta,\\lambda)}{\\bigtriangledown \\beta_{j,n}} = \\frac{x_{dn}}{\\beta_{j,n}}+\\lambda.\n",
    "$$\n",
    "\n",
    "Setting the derivative to zero:\n",
    "\n",
    "$$\n",
    "\\frac{x_{dn}}{\\beta_{j,n}}+\\lambda = 0\n",
    "$$\n",
    "Solving for $\\beta_{j,n}$:\n",
    "$$\n",
    "\\beta_{j,n} = - \\frac{x_{dn}}{\\lambda}\n",
    "$$\n",
    "<!-- Next, taking the derivative with respect to $\\lambda$:\n",
    "$$\n",
    "\\frac{\\bigtriangledown \\mathcal{J}_d(\\beta,\\lambda)}{\\bigtriangledown \\lambda} = \\sum_{n=1}^{N}\\beta_{j,n}-1\n",
    "$$\n",
    "Setting the derivative to zero:\n",
    "$$\n",
    "\\sum_{n=1}^{N}\\beta_{j,n}-1 =0\n",
    "$$\n",
    "Substituting the expression for $\\beta_{j,n}$: -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execrise 1.2: Implementation of Naïve Bayes in scikit-learn (10 points)\n",
    "\n",
    "In this exercise, you will learn the basics of using scikit-learn to implement a Naïve Bayes classifier. We will use the [Sentiment Polarity Dataset Version 2.0](https://www.cs.cornell.edu/people/pabo/movie-review-data/) for this exercise. This dataset contains 1000 positive and 1000 negative reviews. We have provided the code for dataset preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the dataset\n",
    "\n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "nltk.download('movie_reviews', download_dir='.', quiet=True)\n",
    "reviews = load_files('./corpora/movie_reviews', shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment analysis: `neg` for negative sentiment, `pos` for positive sentiment\n",
    "reviews.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of reviews\n",
    "len(reviews.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "reviews_train, reviews_test, y_train, y_test = train_test_split(\n",
    "    reviews.data, reviews.target, test_size=0.20, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset preprocessing: convert reviews to a matrix of token counts\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer().fit(reviews.data) \n",
    "X_train = count_vect.transform(reviews_train).toarray()\n",
    "X_test = count_vect.transform(reviews_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2.1 (8 points)\n",
    "Train the multinomial Naïve Bayes model on the training set and test it on the test set. Report the accuracy of the model on the test set.\n",
    "You would be able to achieve accuracy of around 80% on the test set.\n",
    "\n",
    "(Hint: Refer to the [scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) for more details on how to use the `MultinomialNB` class.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8175\n"
     ]
    }
   ],
   "source": [
    "# Train and test with MultinomialNB\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# TODO: Use the `MultinomialNB` class to train the model on the training set and test it on the test set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# TODO: Report the accuracy of the model on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2.2 (2 points)\n",
    "There are two functions of the Naïve Bayes classifier in order to get the probabilities of the predictions: `predict_proba` and `predict_log_proba`. What is the difference between them? What is the advantage of using `predict_log_proba` over `predict_proba`?\n",
    "\n",
    "(Hint: If you are unsure about this question, please proceed to Exercise 1.3.1 and come back to this question later.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TODO: Write your answer here]**\n",
    "\n",
    "Difference：\n",
    "  predict_proba returns the estimated probabilities of the predicted classes .The probabilities are normalized, meaning that the sum of probabilities for each sample will be equal to 1.The probabilities are in their original scale (not logarithmic)\n",
    "predict_log_proba returns the logarithm of the estimated probabilities of the predicted classes. \n",
    "\n",
    "Advantage of  using `predict_log_proba` over `predict_proba`:\n",
    "a.Taking logarithms can help prevent underflow or loss of precision when dealing with very small probabilities.\n",
    "b. Logarithms can simplify calculations.\n",
    "c.  predict_log_proba can be compared more easily.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3: Your Implementation of Naïve Bayes (30 points)\n",
    "\n",
    "In this exercise, you will implement a Naïve Bayes classifier by yourself and compare it with the scikit-learn implementation. You will use the same dataset as in Exercise 1.2.\n",
    "We have provided a code skeleton for your implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.3.1 (24 points)\n",
    "Implement the `fit`, `predict_proba`, and `predict_log_proba` methods in the `NaiveBayes` class, according to what we have learned from lectures.\n",
    "Each implementation is worth 8 points.\n",
    "Please try to optimize for efficiency. Your code should run in seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes(object):\n",
    "    \"\"\"\n",
    "    Your implementation of Naive Bayes classifier.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=1.0):\n",
    "        \"\"\"\n",
    "        Initialize the Naive Bayes classifier.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        alpha : float, default=1.0\n",
    "            Additive (Laplace/Lidstone) smoothing parameter\n",
    "            (0 for no smoothing).\n",
    "        \"\"\"\n",
    "\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the Naive Bayes classifier on the training set (X, y).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Training vectors, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like, shape (n_samples,)\n",
    "            Target values.\n",
    "        \"\"\"\n",
    "\n",
    "        self.n_features = X.shape[1]\n",
    "        self.n_samples = X.shape[0]\n",
    "        self.n_classes = np.unique(y).shape[0]\n",
    "\n",
    "        self.beta = np.zeros((self.n_classes, self.n_features))\n",
    "        self.pi = np.zeros(self.n_classes)\n",
    "\n",
    "        # TODO: Given (X, y), compute the parameters `beta` and `pi`\n",
    "        # (Hint: Calculate `beta` according to the frequencies of words\n",
    "        #    and `pi` according to the class frequencies.\n",
    "        #    Remember to consider `alpha` for the Laplace smoothing.)\n",
    "        \n",
    "        for i in range(self.n_samples):\n",
    "            if y[i] == 1:\n",
    "#                 self.pi[1] += 1\n",
    "                self.beta[1] += X[i]\n",
    "            else:\n",
    "#                 self.pi[0] += 1\n",
    "                self.beta[0] += X[i]\n",
    "\n",
    "#         self.pi /= self.n_samples\n",
    "        self.beta += self.alpha  # Add Laplace smoothing\n",
    "#         self.beta[1] += self.alpha  # Add Laplace smoothing\n",
    "        self.beta /= np.sum(self.beta, axis=1)[:, np.newaxis]  # 归一化\n",
    "        \n",
    "        unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "        total_samples = y.size\n",
    "        for class_label, class_count in zip(unique_classes, class_counts):\n",
    "            self.pi[class_label] = class_count / total_samples\n",
    "            \n",
    "\n",
    "        self.log_beta = np.log(self.beta)\n",
    "        self.log_pi = np.log(self.pi)\n",
    "        \n",
    "        \n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Return posterior probabilities of classification for X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Test vectors, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        y_prob : array-like, shape (n_samples, n_classes)\n",
    "            Posterior probabilities of classification per class.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Given `X``, return the posterior probabilities of classification\n",
    "        # (Hint: Use `beta`` and `pi`. Remember to normalize the probabilities.)\n",
    "        n_samples, _ = X.shape\n",
    "        probabilities = np.zeros((n_samples, 2))\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            probabilities[i, 0] = np.prod(self.beta[0] ** (1 - X[i]) * (1 - self.beta[0]) ** X[i]) * self.pi[0]\n",
    "            probabilities[i, 1] = np.prod(self.beta[1] ** (1 - X[i]) * (1 - self.beta[1]) ** X[i]) * self.pi[1]\n",
    "\n",
    "#         probabilities /= np.sum(probabilities, axis=1)[:, np.newaxis] \n",
    "        return probabilities\n",
    "    \n",
    "        \n",
    "\n",
    "    def predict_log_proba(self, X):\n",
    "        \"\"\"\n",
    "        Return posterior log probabilities of classification for X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Test vectors, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        y_log_prob : array-like, shape (n_samples, n_classes)\n",
    "            Posterior log probabilities of classification per class.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Given X, return the posterior log probabilities of classification\n",
    "        # (Hint: Use `log_beta`` and `log_pi`.)\n",
    "\n",
    "        log_probabilities = []\n",
    "        for sample in X:\n",
    "            class_scores = []\n",
    "            for class_label in range(2):\n",
    "                # Calculate the probability score under a given category\n",
    "                score = np.sum(np.log(self.beta[class_label]) * sample +\n",
    "                               np.log(1 - self.beta[class_label]) * (1 - sample)) + np.log(self.pi[class_label])\n",
    "                class_scores.append(score)\n",
    "\n",
    "            # The probability scores are normalized and converted to logarithmic probabilities\n",
    "            log_scores = class_scores - np.max(class_scores)\n",
    "            log_probabilities.append(log_scores - np.log(np.sum(np.exp(log_scores))))\n",
    "\n",
    "        return np.array(log_probabilities)\n",
    "    \n",
    "\n",
    "    def predict(self, X):\n",
    "        log_probabilities = self.predict_log_proba(X)\n",
    "        return np.argmax(log_probabilities, axis=1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = NaiveBayes()\n",
    "my_clf.fit(X_train, y_train)\n",
    "\n",
    "# Sanity checks\n",
    "assert my_clf.n_features == X_train.shape[1]\n",
    "assert my_clf.n_samples == X_train.shape[0]\n",
    "assert my_clf.n_classes == np.unique(y_train).shape[0]\n",
    "assert my_clf.beta.shape == (my_clf.n_classes, my_clf.n_features)\n",
    "assert my_clf.pi.shape == (my_clf.n_classes,)\n",
    "assert np.isclose(my_clf.pi.sum(), 1)\n",
    "assert np.allclose(my_clf.beta.sum(axis=1), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.3.2 (6 points)\n",
    "\n",
    "Compare the performance of your implementation with sklearn's implementation on the test set.\n",
    "Report the accuracy of both implementations on the test set.\n",
    "Ideally, you should be able to achieve accuracy of around 80% on the test set, similar to the scikit-learn implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8175\n"
     ]
    }
   ],
   "source": [
    "# TODO: Report the accuracy of your implementation on the test set\n",
    "y_pred = my_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Logistic Regression (50 points)\n",
    "\n",
    "In this problem, we review the classification model known as logistic regression. This model is motivated from a probabilistic perspective, hence we start with this formulation. In the following, we assume that:\n",
    "- Data (boldfont, uppercase X) $\\mathbf{X} \\in \\mathbb{R}^{n\\times d}$, $n$ is the number of data points and $d$ the number of features.\n",
    "- $\\mathbf{x}_i$ is a single data point and $\\mathbf{x}_i \\in \\mathbb{R}^d$.\n",
    "- $\\mathbf{Y} \\in \\mathbb{R}^n$ are the labels of the data points, $Y_i$ is the label of $\\mathbf{x}_i$.\n",
    "- We denote (uppercase letter) $X,Y,Z$,... to be __random variables__, which are measurable maps from the sample space to the real line: $X: \\Omega \\rightarrow \\mathbb{R}$\n",
    "- We denote $P_X$ to be the __probability distribution__ associated with the random variable $X$.\n",
    "- We denote $f_X$ to be the __probability density function (pdf)__ associated with the random variable $X$, if it exists. If the random variable is discrete, then we also use $P_X$ to denote its __probability mass function (pmf)__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Maximum Likelihood Formulation (12 points)\n",
    "\n",
    "Maximum Likelihood Estimation (MLE) is the most standard probabilistic learning framework. In this formulation, we:\n",
    "- Assume that __conditional distribution of label given data__, $P(\\mathbf{Y}\\mid\\mathbf{X})$, follows a parametric probabilistic distribution.\n",
    "- Assume that data pairs are sampled __independently and identically (i.i.d)__ from the distribution. This means $P_{Y\\mid X} := P(\\mathbf{Y}\\mid\\mathbf{X}) = \\prod_{i=1}^n P(\\mathbf{y}_i\\mid\\mathbf{x}_i)$.\n",
    "\n",
    "__As a technical note__, here $P$ is the probability distribution for the random variable $Y\\mid\\mathbf{X}$, not the _probability density function (pdf)_; however, for well-behaved distributions, such as those from the __exponential family__ (including Gaussian, Bernoulli, Poisson, Exponential, etc.), we can just use their pdfs in the case of independence. This means if i.i.d assumption holds, then the joint density function factorizes:\n",
    "$$\n",
    "f_{X}(x_1,x_2,\\cdots, x_n) = f_{X_1,X_2,\\cdots, X_n}(x_1,x_2,\\cdots, x_n) = \\prod_{i=1}^n f_{X_i}(x_i)\n",
    "$$\n",
    "\n",
    "__Example__: In the case of linear regression, we have that $P_{y_i\\mid\\mathbf{X}_i} \\sim \\mathcal{N}(y_i; W^\\top \\mathbf{X}_i + b_i, \\Sigma)$. In this case we have\n",
    "$$\n",
    "f_{Y\\mid X}(x_1, x_2, \\cdots, x_n, y_1, \\cdots, y_n) = \\prod_{i=1}^n f_{Y_i\\mid X_i}(x_i) = \\prod_{i=1}^n \\frac{1}{(2\\pi)^{d/2}|\\Sigma|^{1/2}}\\exp \\left\\{-\\frac{1}{2} (y_i - W^\\top \\mathbf{x}_i - b_i)^\\top \\Sigma^{-1} (y_i - W^\\top \\mathbf{x}_i-b_i) \\right\\}\n",
    "$$\n",
    "\n",
    "To perform a MLE inference, we need to obtain the __likelihood function__, which for exponential family distributions, can simply be written as the joint density function above, but now we change the notation since for likelihood function, __parameters of the distributions are treated as inputs__, e.g.:\n",
    "$$\n",
    "L(W, b, \\Sigma) = \\prod_{i=1}^n \\frac{1}{(2\\pi)^{d/2}|\\Sigma|^{1/2}}\\exp \\left\\{-\\frac{1}{2} (y_i - W^\\top \\mathbf{x}_i - b_i)^\\top \\Sigma^{-1} (y_i - W^\\top \\mathbf{x}_i-b_i) \\right\\}\n",
    "$$\n",
    "\n",
    "However, product term is tricky to deal with, we hence need __log-likelihood__ function. $l(W,b,\\Sigma) = \\log L(W,b,\\Sigma)$ to turn the product into summation. From their on, we can invoke any optimization algorthm (or do it by hand), to maximize the log-likelihood function.\n",
    "\n",
    "Now, the exercise is to write down the formulation of MLE for the following two classes of distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.1.1 (3 points)\n",
    "\n",
    "Write down the log-likelihood function for $n$ i.i.d random samples from the Bernoulli distribution, which has distribution function\n",
    "$$P_X(x_i;p) = p^{x_i}(1-p)^{(1-x_i)}$$\n",
    "where $p\\in [0,1]$ and $x_i \\in \\{0,1\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TODO: Write your answer here]**\n",
    "\n",
    "$$\n",
    "L(p) = log(\\prod_{i=1}^n P_X(x_i,p)) \\\\\n",
    "    = log(prod_{i=1}^n p^{x_i}(1-p)^{1-x_i}) \\\\\n",
    "   = \\sum _{i=1}^n x_i log(p) + (1-x_i)log(1-p)\n",
    "$$\n",
    "Where $L(p)$ represents the log-likelihood function for the observed data $x_1, x_2, \\ldots, x_n$ given the parameter $p$. The goal of maximum likelihood estimation would be to find the value of $p$ that maximizes this log-likelihood function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.1.2 (3 points)\n",
    "\n",
    "Write down the log-likelihood function for $n$ i.i.d random samples from the Poisson distribution, which has distribution function\n",
    "$$P_X(x_i; \\lambda) = \\frac{\\lambda^{x_i} e^{-\\lambda}}{{x_i}!}$$\n",
    "where $x_i \\in \\{1,2,\\cdots,\\}$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TODO: Write your answer here]**\n",
    "\n",
    "$$L(p) = ∏𝑖=1^𝑛 𝑃_𝑋(𝑥_𝑖; 𝑝)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.1.3 (3 points)\n",
    "\n",
    "Write down the __negative log-likelihood__ function for the logistic regression model applied to $n$ data points, where for each observed pair $(\\mathbf{x}_i, y_i)$, we assume that $P_{y_i\\mid X_i} \\sim \\text{Bernoulli}(\\sigma(W^\\top \\mathbf{x}_i))$.\n",
    "\n",
    "(Hint: Refer to Exercise 2.1.1 for the parametric form. Also you don't need to write down exact formula for the sigmoid function $\\sigma$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TODO: Write your answer here]**\n",
    "$$𝐿(𝑊) = -∑𝑖=1^𝑛 [𝑦_𝑖 log(𝜎(𝑊^⊤𝐱_𝑖)) + (1−𝑦_𝑖) log(1 − 𝜎(𝑊^⊤𝐱_𝑖))]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.1.4 (3 points)\n",
    "\n",
    "Suppose you want to perform maximum likelihood inference for Gaussian, Poisson, and Bernoulli random variables. What would be the difference, in terms of optimization procedure, when you deal with these three random variables?\n",
    "\n",
    "(Hint: Think about the values the parameters of these distributions can take.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TODO: Write your answer here]**\n",
    "\n",
    "Difference: \n",
    "```  \n",
    "Gaussian,the likelihood function is typically expressed as the product of the probability density function values for each observed data point. \n",
    "Poisson,the likelihood function is expressed as the product of the probability mass function values for each observed count.\n",
    "Bernoulli, the likelihood function is expressed as the product of the probability mass function values for each observed binary outcome.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Implemention of Logistic Regression (38 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.2.1 (8 points)\n",
    "Analytically calculate the gradient of logistic regression negative log-likelihood with respect to parameter $W$. Show all of your steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TODO: Write your answer here]**\n",
    "\n",
    "\n",
    "define the logistic regression negative log-likelihood function for $𝑛$ data points:\n",
    "\n",
    "$𝐿(𝑊) = -∑𝑖=1^𝑛 [𝑦_𝑖 log(𝜎(𝑊_⊤𝐱_𝑖)) + (1−𝑦_𝑖) log(1 − 𝜎(𝑊^⊤𝐱_𝑖))]$\n",
    "\n",
    "where $𝑊$ is the parameter vector, $𝐱_𝑖$ is the feature vector for the $𝑖$-th data point, and $𝑦_𝑖$ is the corresponding binary label (0 or 1).\n",
    "\n",
    "To calculate the gradient, we need to differentiate $𝐿(𝑊)$ with respect to each component of $𝑊$. Let's consider the $𝑘$-th component of $𝑊$. We will denote it as $𝑊[𝑘]$.\n",
    "\n",
    "Step 1: Differentiate the sigmoid function $𝜎(𝑊^⊤𝐱)$ with respect to $𝑊[𝑘]$:\n",
    "\n",
    "$𝜕𝜎(𝑊^⊤𝐱) / 𝜕𝑊[𝑘] = 𝜎(𝑊^⊤𝐱) (1 - 𝜎(𝑊^⊤𝐱)) 𝜕(𝑊^⊤𝐱) / 𝜕𝑊[𝑘]\n",
    "= 𝜎(𝑊^⊤𝐱) (1 - 𝜎(𝑊^⊤𝐱)) 𝑥[𝑘]$\n",
    "\n",
    "Step 2: Differentiate the log-likelihood function $𝐿(𝑊)$ with respect to $𝑊[𝑘]$:\n",
    "\n",
    "\n",
    "$𝜕𝐿(𝑊) / 𝜕𝑊[𝑘] = -∑𝑖=1^𝑛 [𝑦_𝑖 𝜕log(𝜎(𝑊^⊤𝐱_𝑖)) / 𝜕𝑊[𝑘] + (1−𝑦_𝑖) 𝜕log(1 − 𝜎(𝑊^⊤𝐱_𝑖)) / 𝜕𝑊[𝑘]]$\n",
    "\n",
    "Using the chain rule, we can express the partial derivatives in terms of the derivatives of the sigmoid function:\n",
    "\n",
    "\n",
    "$𝜕log(𝜎(𝑊^⊤𝐱^𝑖)) / 𝜕𝑊[𝑘] = 𝜕log(𝜎(𝑊^⊤𝐱^𝑖)) / 𝜕𝜎(𝑊^⊤𝐱_𝑖) * 𝜕𝜎(𝑊^⊤𝐱_𝑖) / 𝜕𝑊[𝑘]\n",
    "= 𝑦_𝑖 (1 - 𝜎(𝑊^⊤𝐱_𝑖)) 𝑥[𝑘]$\n",
    "\n",
    "$𝜕log(1 − 𝜎(𝑊^⊤𝐱_𝑖)) / 𝜕𝑊[𝑘] = 𝜕log(1 − 𝜎(𝑊^⊤𝐱_𝑖)) / 𝜕𝜎(𝑊^⊤𝐱_𝑖) * 𝜕𝜎(𝑊^⊤𝐱_𝑖) / 𝜕𝑊[𝑘]\n",
    "= - (1 - 𝑦_𝑖) 𝜎(𝑊^⊤𝐱_𝑖) 𝑥[𝑘]$\n",
    "\n",
    "Step 3: Substitute the expressions for the partial derivatives into the gradient expression:\n",
    "\n",
    "$𝜕𝐿(𝑊) / 𝜕𝑊[𝑘] = -∑𝑖=1^𝑛 [(𝑦_𝑖 - 𝜎(𝑊^⊤𝐱_𝑖)) 𝑥[𝑘]]$\n",
    "\n",
    "represents the contribution of each data point to the gradient calculation. It indicates how much each data point influences the update of the parameter $𝑊[𝑘]$ during the optimization process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following exercises, we load a sample dataset, and then implement a logistic regression model by hand; in the end, we compare the prediction performance with a standard logistic regression model from the scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 2)\n",
      "(99, 1)\n"
     ]
    }
   ],
   "source": [
    "sample_data = pd.read_csv(\"sample_data.txt\", delimiter=\",\")\n",
    "n,d = sample_data.shape\n",
    "sample_data.columns = [\"score_1\", \"score_2\", \"label\"]\n",
    "X = sample_data[[\"score_1\", \"score_2\"]].values\n",
    "y = sample_data[\"label\"].values.reshape(-1,1)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "W_init = np.random.randn(d,1)\n",
    "W_init.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.2.2 (10 points)\n",
    "Implement a logistic regression model by hand, by specifying the following functions:\n",
    "- `sigmoid(x)` which implements the sigmoid function\n",
    "- `cost_function(W, X, y)`, which returns the negative log-likelihood and the gradient with respect to parameter `W`\n",
    "\n",
    "(Hint: Tou may want to deal with numerical issues with `log` with something like `eps=1e-6`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    # TODO: Implement the sigmoid function\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W: Model parameters of shape (d,1)\n",
    "# X: Input of shape (N,d)\n",
    "# y: Input of shape (N,1)\n",
    "# Returns: Negative-log-likelihood, gradient\n",
    "def cost_function(W, X, y):\n",
    "    # TODO: Implement the negative log-likelihood function and its gradient with respect to parameter `W`\n",
    "    # Number of data points\n",
    "    n = X.shape[0]\n",
    "\n",
    "    # Add a column of ones to X for the bias term\n",
    "    X = np.column_stack((np.ones((n, 1)), X))\n",
    "\n",
    "    # Compute the linear transformation of input features\n",
    "    z = np.dot(X, W)\n",
    "\n",
    "    # Compute the sigmoid of the linear transformation\n",
    "    h = sigmoid(z)\n",
    "\n",
    "    # Compute the negative log-likelihood\n",
    "    J = -np.mean(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "\n",
    "    # Compute the gradient\n",
    "    gradient = np.dot(X.T, (h - y)) / n\n",
    "\n",
    "    return J, gradient\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.2.3 (6 points)\n",
    "\n",
    "Implement gradient descent and use it to train the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Gradient descent algorithm: update the parameter `W` at each iteration\n",
    "Returns: \n",
    "    - A `List` recording losses at each iteration\n",
    "    - The final optimal value of `W`\n",
    "\"\"\"\n",
    "def gradient_descent(X, y, W, learning_rate, n_iters):\n",
    "    # TODO: Implement the gradient descent algorithm\n",
    "    # Initialize the parameter vector\n",
    "    records = []\n",
    "    # Perform gradient descent\n",
    "    for iteration in range(n_iters):\n",
    "        # Compute the negative log-likelihood and gradient\n",
    "        cost, gradient = cost_function(W, X, y)\n",
    "\n",
    "        # Update the parameters\n",
    "        W = W - (learning_rate * gradient)\n",
    "\n",
    "        records.append((cost, W))\n",
    "    \n",
    "    return records, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Parameters = [(nan, array([[ 0.46414515],\n",
      "       [-0.63780094],\n",
      "       [ 0.91474864]])), (nan, array([[ 0.44700916],\n",
      "       [-0.88650582],\n",
      "       [-0.19611297]])), (48.66397586470026, array([[0.50761522],\n",
      "       [3.64191374],\n",
      "       [4.28609322]])), (nan, array([[0.46822128],\n",
      "       [1.57457193],\n",
      "       [2.15802151]])), (nan, array([[ 0.42882734],\n",
      "       [-0.49276987],\n",
      "       [ 0.0299498 ]])), (20.71237988931243, array([[0.48943339],\n",
      "       [4.03564931],\n",
      "       [4.51215518]])), (nan, array([[0.45003945],\n",
      "       [1.96830751],\n",
      "       [2.38408347]])), (nan, array([[ 0.41064551],\n",
      "       [-0.09903429],\n",
      "       [ 0.25601176]])), (3.5778386513386518, array([[ 0.37260584],\n",
      "       [-2.04975555],\n",
      "       [-1.82006295]])), (174.1746836673115, array([[0.4332119 ],\n",
      "       [2.47866401],\n",
      "       [2.66214323]]))]\n",
      "Iteration 1: Parameters = [[0.4332119 ]\n",
      " [2.47866401]\n",
      " [2.66214323]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\Dell\\anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "# TODO: Run gradient descent and obtain the records alongside optimal `W` \n",
    "\n",
    "W = W_init # np.zeros(d + 1)\n",
    "learning_rate = 0.1\n",
    "num_iterations = 10\n",
    "# Train the logistic regression model and obtain records\n",
    "records = gradient_descent(X, y, W, learning_rate, num_iterations)\n",
    "\n",
    "# Print the records alongside the optimal parameters\n",
    "for iteration, params in enumerate(records):\n",
    "    print(f'Iteration {iteration}: Parameters = {params}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.2.4 (6 points)\n",
    "\n",
    "Plot the training curve (y-axis as the negative log-likelihood, and x-axis as training iterations), and experiment on different learning rates and `n_iters` to ensure convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\Dell\\anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x648 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Use matplotlib to plot the losses and show convergence\n",
    "learning_rates = [0.1, 0.01, 0.001]\n",
    "num_iterations = [100, 1000, 5000]\n",
    "\n",
    "# Plot the training curve for different learning rates and number of iterations\n",
    "fig, axs = plt.subplots(len(learning_rates), len(num_iterations), figsize=(12, 9))\n",
    "\n",
    "for i, lr in enumerate(learning_rates):\n",
    "    for j, iterations in enumerate(num_iterations):\n",
    "        # Train the logistic regression model and obtain records\n",
    "        records, optimal_params = gradient_descent(X, y, W_init, lr, iterations)\n",
    "\n",
    "        # Extract the cost values from the records\n",
    "        costs = [record[0] for record in records]\n",
    "\n",
    "        # Plot the training curve\n",
    "        ax = axs[i, j]\n",
    "        ax.plot(range(iterations), costs)\n",
    "        ax.set_title(f'Learning Rate: {lr}, Iterations: {iterations}')\n",
    "        ax.set_xlabel('Training Iterations')\n",
    "        ax.set_ylabel('Negative Log-Likelihood')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.2.5 (8 points)\n",
    "\n",
    "Use the `sklearn.linear_model.LogisticRegression` model to fit the given `X` and `y`, then report the optimum values obtained from this model and compare with the result from Exercise 2.2.3.\n",
    "Are the optimal value of parameters similar? If so, explain why. If not, explain what may cause the difference between your implementation and the one from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters from sklearn: [-24.76261953   0.20251777   0.19901181]\n",
      "Optimal parameters from Exercise 2.2.3: [[-7.06131193]\n",
      " [ 2.85984684]\n",
      " [ 2.97938707]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\Dell\\anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\Dell\\anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "# TODO: scikit-learn logistic regression\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Fit Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Obtain the optimal parameter values\n",
    "optimal_params_sklearn = np.concatenate((model.intercept_, model.coef_.flatten()))\n",
    "\n",
    "# Obtain the optimal parameter values from Exercise 2.2.3\n",
    "optimal_params_custom = gradient_descent(X, y,W_init, learning_rate=0.1, n_iters=1000)[-1]\n",
    "\n",
    "print(\"Optimal parameters from sklearn:\", optimal_params_sklearn)\n",
    "print(\"Optimal parameters from Exercise 2.2.3:\", optimal_params_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TODO: Write your answer here]**\n",
    "```\n",
    "Their results are different, probably because of the choice of hyperparameters.\n",
    "\n",
    "The learning rate and number of iterations used in the gradient descent algorithm for Exercise 2.2.3 can affect convergence and the resulting optimal parameter values. Choosing appropriate hyperparameters is crucial for achieving similar results.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Gaussian Mixture Model (70 points + 10 bonus points)\n",
    "\n",
    "In this problem, we will review a commonly used __latent variable model__ called Gaussian Mixture Model (GMM). In particular, we will focus on the property of learning this model, first from the perspective of MLE and then from the perspective of surrogate optimization, using what is known as the __Expectation Maximization (EM)__ algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Full Distribution of GMM (6 points)\n",
    "\n",
    "We know that for _generative modeling_, the dataset is assumed to be generated from some probabilistic distribution, and the goal of GMM is to estimate the underlying distribution of the dataset. Here the assumption is implicitly that the data is generated by a probability distribution smooth enough, such that we can estimate its probability density function (pdf). Hence the terminology for this task is known as __density estimation__. A straightforward application of density estimation is the task of __clustering__, e.g., determining the possible __modes__ of the probability density function (each cluster center can be seen as the mode of a pdf). Therefore, from this perspective, we can make the following observations about K-Means and GMM:\n",
    "\n",
    "- K-Means is an algorithm that targets the task of clustering specifically, while GMM is more powerful in that it deals with density estimation, and by this virtue it can also be used for clustering.\n",
    "- In the context of clustering, GMM assigns data points _softly_, that is, with some probability, to a cluster, whereas K-means provides _hard assignments_ of elements to clusters.\n",
    "\n",
    "Suppose that the dataset contains $n$ elements $\\{x_1, \\cdots, x_N\\}$ and we assume $k$ cluster centers (or distribution modes). Now we take a look at the generative modeling story that GMM is telling: as a latent variable model, each observed data point $\\mathbf{x}_i$ is associated with two random variables $Z_i, X_i$, such that $P_{X_i,Z_i} = P_{Z_i}P_{X_i\\mid Z_i}$ where:\n",
    "\n",
    "\n",
    "- $Z_i \\sim Cat(\\pi_1, \\cdots, \\pi_k)$, where $k$ represents $k$ pdf modes (clusters) and $\\sum_{j=1}^k \\pi_j = 1$; this random variable is quantifies the event \\{$\\mathbf{x}_i$ belongs to cluster $j$\\}, and $P(Z_j = i) = \\pi_i$.\n",
    "\n",
    "Now comes the trickier bit, where we specify a __conditional distribution__ $X_i\\mid Z_i=j$. This means __after observing that $\\mathbf{x}_i$ is in cluster $j$, what is the distribution of $x_i$?__. The GMM assumes this follows a Gaussian with mean and variance determined by the clsuter $j$:\n",
    "\n",
    "- $X_i\\mid Z_i = j \\sim \\mathcal{N}(\\mu_j, \\Sigma_j)$, where the index $j \\in \\{1,\\cdots, N\\}$ and index $j\\in\\{1,\\cdots, k\\}$. We can see that each random variable $X_i\\mid Z_i=j$ is distributed as a Gaussian, whose parameters are determined by the cluster it belongs to.\n",
    "\n",
    "The plate diagram for this _Probabilistic Graphical Model_ is given below, where the empty circle represents the latent variable (since we cannot observe the clusters a priori).\n",
    "\n",
    "![](bishop-gaussian-mixture.png)\n",
    "\n",
    "This plate diagram tells us that there are in total $2N$ random variables, two for each observed data point. It also allows us to write down the joint density function, where again we have the i.i.d assumption of each random variable pair $(X_i,Z_i)$ and we denote the full joint distribution as $P_{XZ}$ (and the full joint pdf as $f_{XZ}$) and the individual joint distribution to be $P_{X_iZ_i}$(and the individual joint pdf to be $f_{X_iZ_i}$):\n",
    "\n",
    "$$\n",
    "f_{X_iZ_i}(\\mathbf{\\mathbf{x}_i}, k) = P(Z_i = k) f_{X}(\\mathbf{x_i} \\mid \\mu_k, \\Sigma_k) = \\pi_k \\mathcal{N}(\\mathbf{x}; \\mu_k, \\Sigma_k)\n",
    "$$\n",
    "\n",
    "\n",
    "__Please strictly follow the notation used in this notebook, as your true understanding of the model should not change with a change of notation__!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.1.1 (3 points)\n",
    "\n",
    "Write down the full derivation of the joint density function $f_{XZ}$ from the formula above.\n",
    "\n",
    "(Hint: Write down the correct pdf for each random variable, then use the assumption of i.i.d to factorize it. Note that $\\mathbf{x}_i \\in \\mathbb{R}^d$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TODO: Write your answer here]**\n",
    "\n",
    "To obtain the joint density function 𝑓𝑋𝑍, we need to multiply the individual joint PDFs together for all pairs $(𝑋_𝑖, 𝑍_𝑖)$.\n",
    "$$𝑓_{𝑋𝑍} = 𝑓𝑋_₁𝑍_₁ ⋅ 𝑓𝑋_₂𝑍_₂ ⋅ ... ⋅ 𝑓𝑋_𝑁𝑍_𝑁.$$\n",
    "Substituting the expression for $𝑓𝑋_𝑖𝑍_𝑖$, have:\n",
    "$$𝑓_{𝑋𝑍} = (𝑃(𝑍_1=𝑘)𝑓𝑋_1(𝐱_1∣𝜇_𝑘,Σ𝑘)) ⋅ (𝑃(𝑍_2=𝑘)𝑓𝑋_2(𝐱_2∣𝜇_𝑘,Σ𝑘)) ⋅ ... ⋅ (𝑃(𝑍_𝑁=𝑘)𝑓𝑋𝑁(𝐱_𝑁∣𝜇_𝑘,Σ𝑘)).$$\n",
    "Since each pair $(𝑋_𝑖, 𝑍_𝑖)$ is assumed to be independent, we can rewrite the joint density function as a product of the marginal densities for 𝑍𝑖 and the conditional densities for $𝑋_𝑖$ given $𝑍_𝑖=𝑘$:\n",
    "\n",
    "$$𝑓_{𝑋𝑍} = (𝑃(𝑍_1=𝑘) ⋅ 𝑃(𝑍_2=𝑘) ⋅ ... ⋅ 𝑃(𝑍_N=𝑘)) ⋅ (𝑓𝑋_1(𝐱_1∣𝜇_𝑘,Σ𝑘) ⋅ 𝑓𝑋_2(𝐱_2∣𝜇_𝑘,Σ𝑘) ⋅ ... ⋅ 𝑓𝑋_N(𝐱_𝑁∣𝜇_𝑘,Σ𝑘)).$$\n",
    "\n",
    "Noting that the terms in parentheses can be simplified as:\n",
    "$(𝑃(𝑍_1=𝑘) ⋅ 𝑃(𝑍_2=𝑘) ⋅ ... ⋅ 𝑃(𝑍𝑁=𝑘)) = 𝜋_𝑘^𝑁,$\n",
    "\n",
    "rewrite the joint density function as:\n",
    "\n",
    "$$𝑓_{𝑋𝑍} = 𝜋_𝑘^𝑁 ⋅ (𝑓𝑋_1(𝐱_1∣𝜇_𝑘,Σ𝑘) ⋅ 𝑓𝑋_2(𝐱_2∣𝜇_𝑘,Σ𝑘) ⋅ ... ⋅ 𝑓_{𝑋𝑁}(𝐱_𝑁∣𝜇_𝑘,Σ𝑘)).$$\n",
    "\n",
    "the full derivation of the joint density function $𝑓_{𝑋𝑍}$\n",
    "$$𝑓_{𝑋𝑍} = 𝜋_1 \\mathcal{N}(𝐱; 𝜇_1,Σ_1) ⋅ 𝜋_2 \\mathcal{N}(𝐱; 𝜇_2,Σ_2) ⋅ ... ⋅ 𝜋_𝑁 \\mathcal{N}(𝐱; 𝜇_𝑁,Σ_𝑁).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.1.2 (3 points)\n",
    "\n",
    "Write down the formula for the marginal joint pdf of $f_X$ using the result from Exercise 3.1.1, where $X$ is the collection of random variables $X_1,\\cdots, X_N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**[TODO: Write your answer here]**\n",
    "\n",
    "To obtain the marginal joint density function $𝑓_𝑋$ of the random variables $𝑋_1, 𝑋_2, ..., 𝑋_𝑁$, we integrate out the random variables $𝑍_1, 𝑍_2, ..., 𝑍_𝑁$ from the joint density $𝑓_{𝑋𝑍}$.\n",
    "\n",
    "the marginal joint density function $𝑓_𝑋$ is obtained by integrating the joint density $𝑓_{𝑋𝑍}$ over all possible values of $𝑍_1, 𝑍_2, ..., 𝑍_𝑁$ :\n",
    "\n",
    "$$𝑓_𝑋(𝐱_1, 𝐱_2, ..., 𝐱_𝑁) = \\int \\int ...\\int  𝑓_{𝑋𝑍} d_{𝑍_1} d_{𝑍_2} ... d_{𝑍_𝑁}.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2: MLE and EM algorithm for GMM (9 points + 10 bonus points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.2.1 (5 points)\n",
    "\n",
    "After obtaining the joint PDF, we now can derive the negative log-likelihood function of the joint pdf. write down the formula for the negative log-likelihood for random variable $X = (X_1,.\\cdots, X_N)$. Then answer the following: why is doing a vanilla MLE for GMM difficult?\n",
    "\n",
    "(Hint: It is okay to Google this, but you need to write down the analytical form of the negative log-likelihood and then say something about it.\n",
    "You may want to read Section 9.2.1 from Christopher Bishop's [_Pattern Recognition and Machine Leanrning_](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TODO: Write your answer here]**\n",
    "The negative log-likelihood function, denoted as $𝐿(𝜃)$, where $𝜃$ represents the parameters of the GMM, is given by:\n",
    "$$𝐿(𝜃) = -∑_i log(𝑓_{𝑋(𝐱ᵢ)})$$\n",
    "where $𝐱_i$ represents the observed data points.\n",
    "\n",
    "For a GMM, the joint PDF $𝑓_𝑋(𝐱_1, 𝐱_2, ..., 𝐱_𝑁)$ is the product of the mixture coefficients and the individual Gaussian PDFs:\n",
    "\n",
    "$$𝑓_𝑋(𝐱_1, 𝐱_2, ..., 𝐱_𝑁) = \\prod_i 𝜋_1\\mathcal{N}(𝐱_i; 𝜇_1, Σ_1) ⋅ 𝜋_2\\mathcal{N}(𝐱_i; 𝜇_2, Σ_2) ⋅ ... ⋅ 𝜋_𝑁\\mathcal{N}(𝐱_i; 𝜇_𝑁, Σ_𝑁).$$\n",
    "\n",
    "Substituting this expression into the negative log-likelihood function, we have:\n",
    "\n",
    "$$𝐿(𝜃) = -∑_i log(\\prod_i 𝜋_1 \\mathcal{N} (𝐱_i; 𝜇_1, Σ_1) ⋅ 𝜋_2 \\mathcal{N}(𝐱_i; 𝜇_2, Σ_2) ⋅ ... ⋅ 𝜋_𝑁 \\mathcal{N}(𝐱_i; 𝜇_𝑁, Σ_𝑁)).$$\n",
    "\n",
    "Using the logarithmic identity $log(𝑎 ⋅ 𝑏) = log(𝑎) + log(𝑏)$, we can rewrite the negative log-likelihood function as:\n",
    "\n",
    "$$𝐿(𝜃) = -∑_i(∑_k log(𝜋_k\\mathcal{N} (𝐱_i; 𝜇_k, Σ_k))).$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.2.2 (4 points)\n",
    "\n",
    "Write down the EM algorithm for GMM (i.e. write down the 4 steps)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TODO: Write your answer here]**\n",
    "\n",
    "1.Initialize the parameters of the GMM, including the number of components ($K$), the means ($\\mu$), the covariance matrices ($Σ$), and the mixing coefficients ($\\pi$).\n",
    "You can randomly initialize the parameters or use a different initialization method like K-means clustering.\n",
    "E-step (Expectation step):\n",
    "\n",
    "2.Calculate the posterior probabilities or responsibilities ($\\gamma$) for each data point and each component of the GMM.\n",
    "The posterior probability $\\gamma(i, k)$ represents the probability that the data point i belongs to the kth component.\n",
    "M-step (Maximization step):\n",
    "\n",
    "3.Update the parameters of the GMM based on the calculated posterior probabilities.\n",
    "Update the means ($\\mu$), covariance matrices ($Σ$), and mixing coefficients ($\\pi$) using the data and the calculated responsibilities ($\\gamma$).\n",
    "\n",
    "4.Repeat steps 2 and 3 until convergence.\n",
    "Convergence can be determined based on a specified number of iterations or when the change in the log-likelihood of the data becomes negligible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.2.3 (10 bonus points)\n",
    "Prove that the EM algorithm guarantees monotonic increase in the log-likelihood using the following theorem (or any version of it, by providing your source citation).\n",
    "\n",
    "__Theorem (Jensen's Inequality)__: If $f:\\mathbb{R}\\rightarrow \\mathbb{R}$ is a concave function, then for any $x_1,\\cdots, x_k$, and any $\\lambda_1,\\cdots, \\lambda_k \\geq 0$, and $\\sum_{i=1}^k \\lambda_k = 1$, the following inequality holds:\n",
    "$$\n",
    "\\sum_{j=1}^m \\lambda_j f(a_j) \\leq f\\left( \\sum_{j=1}^m \\lambda_j a_j \\right)\n",
    "$$\n",
    "\n",
    "__Hints__:\n",
    "- Is the logarithm function a concave function?\n",
    "- You may want to checkout the general case of EM algorithm monotonicity [here](https://www.cs.cmu.edu/~epxing/Class/10708-17/notes-17/10708-scribe-lecture8.pdf). Think about the special case of GMM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TODO: Write your answer here]**\n",
    "\n",
    "In the EM algorithm, the E-step calculates the posterior probabilities or responsibilities ($\\gamma$) for each data point and each component of the GMM. The M-step updates the parameters of the GMM based on these responsibilities. The objective is to maximize the log-likelihood function, which is a concave function.\n",
    "\n",
    "During the E-step, we calculate the expected complete data log-likelihood function, which is the sum of the log-likelihoods of each data point weighted by its responsibility. Using Jensen's Inequality, we can show that the expected complete data log-likelihood is always less than or equal to the complete data log-likelihood:\n",
    "\n",
    "$$∑_{j=1}^𝑚 𝜆_𝑗 log 𝑓(𝑎_𝑗) ≤ log(∑_{𝑗=1}^𝑚 𝜆_𝑗𝑓(𝑎_𝑗))$$\n",
    "\n",
    "Since the log-likelihood function is maximized, the $log(∑𝑗=1𝑚 𝜆𝑗𝑓(𝑎𝑗))$ will be greater than or equal to the log-likelihood at the previous iteration. Therefore, the EM algorithm guarantees a monotonic increase in the log-likelihood function with each iteration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3: EM vs. GD on Convergence (55 points)\n",
    "\n",
    "In this numerical experiment, we study and compare two cases:\n",
    "1. GMM trained using MLE, with gradient descent;\n",
    "2. GMM trained using EM algorithm.\n",
    "\n",
    "We compare these two scenarios' convergence behavior and their overall optimization performance. In particular, we:\n",
    "1. Provide randomzied initial values for the model parameters;\n",
    "2. (Exercise 3.3.1) Ask you to implement the objective / loss function, the negative-log-likelihood;\n",
    "3. (Exercise 3.3.2) Ask you to call optimization algorithm from sklearn to minimize this objective;\n",
    "4. (Exercise 3.3.3) Implement EM algorithm to optimize the objective;\n",
    "5. (Exercise 3.3.4) Observe the convergence behavior in Exercises 3.1.2 and 3.1.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.3.1: GMM with MLE (10 points)\n",
    "\n",
    "In this case, we generate some random data, then ask you to implement the objective function (__log-likelihood__). In this case we use the positive, since EM algorithm is maximizing the log-likelihood, rather than minimizing the negative log-likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generation\n",
    "np.random.seed(1234)\n",
    "def generate_MoG_data(num_data, means, covariances, weights):\n",
    "    \"\"\" Creates a list of data points \"\"\"\n",
    "    num_clusters = len(weights)\n",
    "    data = []\n",
    "    for i in range(num_data):\n",
    "        #  Use np.random.choice and weights to pick a cluster id greater than or equal to 0 and less than num_clusters\n",
    "        k = np.random.choice(len(weights), 1, p=weights)[0]\n",
    "\n",
    "        # Use np.random.multivariate_normal to create data from this cluster\n",
    "        x = np.random.multivariate_normal(means[k], covariances[k])\n",
    "\n",
    "        data.append(x)\n",
    "    return data\n",
    "\n",
    "# Model parameters\n",
    "init_means = [\n",
    "    [5, 0], # mean of cluster 1\n",
    "    [1, 1], # mean of cluster 2\n",
    "    [0, 5]  # mean of cluster 3\n",
    "]\n",
    "init_covariances = [\n",
    "    [[.5, 0.], [0, .5]], # covariance of cluster 1\n",
    "    [[.92, .38], [.38, .91]], # covariance of cluster 2\n",
    "    [[.5, 0.], [0, .5]]  # covariance of cluster 3\n",
    "]\n",
    "init_weights = [1/4., 1/2., 1/4.]  # weights of each cluster\n",
    "\n",
    "# Generate data\n",
    "np.random.seed(4)\n",
    "data = generate_MoG_data(100, init_means, init_covariances, init_weights)\n",
    "data = np.vstack(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAELCAYAAAAP/iu7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAanElEQVR4nO3df4xsZ13H8c93995LO4WmZe6VALJnbPwVFIHcDRJt5JdS0wQqCRhgAC2JWxaMRYQQGJqgMkKAQKsgdFXEZEZMoEWIIUCltESSGvZG+VEBaXFn0z/Qey8VWrex9u7jHzNz2Tt7zsyZmfOc5/x4v5KTbc/cM+fZ2TnP9zzP8z3PY845AQDg00roAgAAqo9gAwDwjmADAPCOYAMA8I5gAwDw7kjoAiQ5fvy4a7VaoYsBAJjDqVOnzjjnTkzuL2ywabVa2t7eDl0MAMAczGwQt59uNACAdwQbAIB3BBsAgHcEGwCAdwQbAIB3BBsAgHcEm4rq9/tqtVpaWVlRq9VSv98PXSQANVbY52ywuH6/r42NDe3t7UmSBoOBNjY2JEntdjtk0QDUFC2bCup0OucDzdje3p46nU6gEgGoO4JNBe3u7s61HwB8I9hU0Nra2lz7AcA3gk0FdbtdNRqNC/Y1Gg11u91AJQJQdwSbCmq329ra2lIURTIzRVGkra0tkgMABGPOudBliLW+vu6Y9RkAysXMTjnn1if3e2/ZmNnVZvYlM3vQzH5oZttm9lzf5wUAFIfXYGNm10n6lKRTkl4k6SWSPi6pMe04AEC1eHuo08xakm6U9Cbn3I0HXvqcr3MCAIrJZ8vm1ZL2JX3Y4zkAACXgM9hcKelbkl5qZvea2SNmdo+Zvc7jOQEABeRzbrQnjLb3SHqrpHs1HLP5gJkdcc7dNHmAmW1I2pB4ABEAqsRny2ZF0mMkXeec+wvn3O3OuU1Jn5X0FjOzyQOcc1vOuXXn3PqJEyc8Fq1cmMEZQNn5DDZnRz9vm9j/eUmPk/R4j+f2IkSlP57BeTAYyDl3fgZnAg6AMvEZbO5O2D9u0ex7PHfmQlX6zOAMoAp8BptPjn5eNbH/Kkn3Oee+5/HcmQtV6Wc1gzNdcQBC8hlsPiPpi5JuNrPXmNnzzWxL0vMl3eDxvF6EmrY/ixmcF22VEaAAZMY5522TdKmkD0r6T0kPS/qapJenOfbkyZOuSKIocpIObVEUeT1vr9dzjUbjgnM2Gg3X6/VSv8ciZc/ivADqR9K2i4sHcTuLsBUt2ISsfHu9nouiyJmZi6Jo7nOaWWywMbPEY0IFVwDllhRsmPV5Dv1+X51OR7u7u1pbW1O32y3FtP2tVkuDweDQ/mazqTNnzsQes7Kyorjvhplpf79UuR0AchRs1ucqabfb2tnZ0f7+vnZ2dgoVaKaNr3S7XR09evTQMQ888EDiOAyrfQLIEsGmAmYlALTbbV166aWHjnv44YcTs+lY7RNAluhGq4CkbrIoirSzsyNpsW6xsnYbAggnqRuNYFMBaQJJmoAEAMtizKbC0oyv0C0GICSCTQWkCSTtdltbW1uKokhmpiiKtLW1lapbjIc7ASyLbrSK8DW+Mk4+ODhVT6PRSB2oANQLYzZYCGM9AObBmA0WEmpOOADVQrDBVDzcCSALBBtMRRYbgCwQbEokRFbYMllsADBGgkBJkBUGoAxIECg5locGUGYEm4z46uIav29c+rG0fFbYPOXm4U4AC4tb5KYIW9EWT5vG18Jqce87uS2zmNk85WblTgBpiJU6/fG1qmXS+2ZV2Se9f7PZPLQyKCt3AkgjKdiQIJABX6taJr2vNHyCf9kpaaa9/0GNRuPQeNEYK3cCOIgEAY98PfiYdPx4qpjJQDPvmEra8u3t7Wl1dTX2tZWVFcZuAMxEsMmArwcf53nfWat1pn3/JOfOnYv9t+fOnZt5nryRyAAUUFzfWhG2Mo3ZOOfOj2scHOfI830XHVOZfP9ms5n4Pr1ez62urhZ67IZEBiAskSBQbXEBQJIzs7neZ1ZlbWaZnOfg+bIM0iQyAGElBRu60RZQtG6afr8vM4t9bd5xo1nT02Q5PrVI198szFINFFRcBCrCVtSWTRG7aZLu5s0s83Jl+fv7aIXQsgHCEt1o2Zj2bEoWFulWSuraGt5LZC+rrq+su+TGZSvazQBQJwSbjEyr2H3MGJCmoizr3byvcvtK1gAwG8EmI9Oe6l+0kpz2hH6a910kSBWhQqYVAlQPwSYjvV4vs8yv8fvNmv8szfvOEzyKVMkXIegByE5SsGG6mgUcP35cZ8+ePbR//GT/PKbN6LzM+y5yzqzPA6B+mK4mQzfddFNmMwbMSsnNYiaCyVRtX8sVAEASgs0CslwqedrzKYu+78Hgcvz4cV177bUXPMuS1TM5AJAW3WiBZb3cc9z7xTEzHfzbs8Q0gCzQjVZQWbaSpPjlo+M45zI7JwDMQsumYtKuUUMyAAAfaNnURJpxlyySDgBgHgSbiolbo+bYsWNqNpt0mQEIhmCTUtFmek4SNwb0kY98RGfOnNH+/n7sCp8A4BtjNilknTEGAFUVfMzGzD5rZs7M3pHXObMSl+G1t7enTqfj5XxlaUUBQFpH8jiJmb1M0lPzOJcPeS7INdmKGi8oJolWFIDS8t6yMbPLJL1f0ht8n8uXLFennCWpFfWKV7yCVg6A0sqjG+3dku52zn0sh3N5EZfh5St9eFprKYtlkwEgBK/BxsyulPQqSa/1eR7fsn7Kf5pZrSWfY0UA4Iu3YGNmRyXdLOm9zrlv+zpPXtrttnZ2dpZKH04z8B/XiprE7MwAysZny+bNki6WlLqvycw2zGzbzLZPnz7tr2QBjAf+D86+HNcldrAVlYTZmQGUjZdgY2ZrkjqSbpD0KDO7bJQooAP/vzp5nHNuyzm37pxbP3HihI+iBTNP+vS4FdXr9XIbKwIAn3y1bK6QdJGknqT7D2yS9MbRfz/F07kLaZH06TzHigDAJy8zCIxaMU+LeemLGgagv9JwneoHk96jSDMIZIGlmAHUQa4zCDjn/ts5d8fkNnp5MPr/xEBTRXmmTwNA0TARZ07oEgNQZ0zECQDITPCJOAEA9UWwAQB4R7ABAHhHsAEAeEewAQB4R7ABAHhHsAEAeEewAQB4R7ABAHhHsAEAeEewQVBpVi8FUH5HQhcA9TVevXS8qNx49VJJTFAKVAwtGwQzz+qlAMqNYINgFlm9FEA5EWwQzNra2lz7AZQXwQbBsHopUB8EGwTD6qVAfbBSJwAgM6zUCQAIhmADAPCOYAMA8I5gAwDwjmADAPCOYAMA8I5gAwDwjmADAPCOYAMA8I5gAwDwjmADAPCOYAMA8I5gAwDwjmADAPCOYAOM9Pt9tVotraysqNVqqd/vhy4SUBlHQhcAKIJ+v6+NjQ3t7e1JkgaDgTY2NiSJxdyADNCyASR1Op3zgWZsb29PnU4nUImAaiHYAJJ2d3fn2g9gPgQbQNLa2tpc+wHMh2ADSOp2u2o0GhfsazQa6na7gUrkF8kQyBvBBpWxTAXabre1tbWlKIpkZoqiSFtbW5VMDhgnQwwGAznnzidDEHDglXOukNvJkycdkFav13ONRsNJOr81Gg3X6/VCF20hvV7PRVHkzMxFUZTp7xFF0QWf03iLoiizc6C+JG27mDrdhq9lz8xeLOllktYl/ZikXUm3SvoT59wDs45fX19329vbXsqG6mm1WhoMBof2R1GknZ2d/Au0hMk0bGnYpZdVS2tlZUVx172ZaX9/f+n3R72Z2Snn3Pqh/R6DzV0aBphPSbpP0tMlvV3StyT9knNu6reaYIN5VKkC9R04qxSYUTxJwcbnmM0LnHO/6ZzrO+fudM7dKOn3JP2ipGd7PC9qqErZZL7TsOuWDIFi8BZsnHOnY3Z/ZfTzib7Oi3qqUgXqO3DWKRkCxZF3NtqzRj+/mfN5EZjvVNsqVaB5BM52u62dnR3t7+9rZ2enlJ8TSiYua8DHpmFr5r8k3Tbl32xI2pa0vba2lnWSBAKpWqZYHnxmowGTsvy+Ke9stIPM7NGS7pD0BEnPcM7dN+sYEgSqgwFpoLiyzn7MPRvtwIkvkvQZSU+T9Czn3NfTHEewqY4qZYoBVZP1zWCIbDSZ2VFJt0h6hqSr0wYaVEuVMsWAqslrElpvwcbMViT1JT1P0jXOubt8nQvFVqVMMaBq8roZ9Nmy+aCkl0h6r6T/MbNnHth+3ON5sQQfWWN5ZooxwSQwn9xuBuOyBrLYJO0oZv6l0fb2WcczN1r+sswaC5FNRdYbsJjKZKMtggSB/GU1UOh7bq8kZL0B4QXLRlsUwSZ/WWWNhar0yXoDwguSjYZyyWqgMNQSy2nLz7gOkD+CDc6LGyg0Mw0Gg7kq5VCpzmkGOlk4DAgkbiCnCBsJAmGMBwolOTNbaLA95ED9rIFOFg5DUVVliiIlJAgEDypJG8EmrLSV8sHgtLq6ev7fbG5uer1wFr0wJwPoeDOzTMsHzKNKmZQEG8wlTaUcd4HkcaEsc2HSskERVel7mRRsGLNBrDTjLp1O54L05oP29vbU6XQO7c9icD7uvEnnm8RsBtVW1uSPUEk1uYqLQEXYaNmElab1kNT6UUwrKO17prFsV9jm5qZbWVk5f9wll1xSyu4KXKjMXVF1aNkEDypJG8EmvEUH25MulKwuqGXep9fruaNHjx469tixY6WolJCszBV2mQPlJIINMjfvmE1Wg/M+xmzKUikhWdmTP8hGI9hgiqRstLgLJcs7z6yz0cpUKSFemVs2VUKwQXBF6CqgZVNdRfh+ITnYkI2G3OS51ECSbrero0ePHtp/7NgxLxlpZc2OKqMifL+QjIk4UTv9fl/XX3+9zp49K0lqNpu66aabMq+UQs1+DYTERJzIXFnv2tvtts6cOXO+eX/mzBkvlf8yzwMBVXMkdAFQTpN37eMJLSVx1z5Siwf1gJRo2WAhRblrL3LrKtTs10AREWywkCLctRd9uQCmxkmvyDcNyAbBBgspwl17UVpX01x88cXn/7vZbJIcEKPoNw3IBsEGC8nirn3Zu9mkVtS8i735MK5AxxlvkvTQQw8FK0+RleGmARmIe/imCBsPdRbfMtNrZPEA3qy52RZ5oG9zc/P8TAirq6tuc3NzruNnlY0HRw8ryzQzVZlOxjcxgwCKJIvKeNrcbIu83+bmZux7LBJwylKBFkEZAjOzE6RHsEGhzKqM095FHpybbdnKfdyimdxWV1fn/v3KUIEWRRkqcv6e6RFssBBfXQfTLt5FKp9ZlUGa32NaC2leZahAi6ToXVS0VNMj2GBuvirMXq/nms1m4hjLIneR08qa9vdIatmMK5V5K8Gsxn8QxsEAmPTdoGVzGMEGc/PRdZA0ztJsNs9X5IveRSbdHaf9PZLGbBYJtrRsyi3NeCB/z3gEG8w0WVlnMQ4yKU3Fn/Rvms1mbDlnXfDzBK+DrZGkLU2wpY+/3JL+fqurqxd874re/RcCwQZTxd3JJVXSy1SYaSr+Xq/njh07dujfHD161G1ubmY+nrNMWX0ci/DSfk9pvR5GsKmgLO+qkirkyYtu2YspbcUfN6YzvrOcN3AsWiks0zqhZVNuy7TA6/43JthUTNZ3VdOWSz7YjZVFckCacqcpzzwthkUC8zKfMXe95Zbm7xei9VqGbjuCTcVkfVc1bYwm68oyzQUzrc88z7vJZWdJKHrFgGSz/n55t2zKcgNDsKmYrO+q0mTf+LqQ4i7qpAtrkTEblEtZgnTelX9Zuu0INhXjKy15fJEv2l21yDmnPR8TV+mUpTLC/Mpy9z6W53exLEknBJuK8X1R5nUXFfJujaBVPGW5ew+hLJ8NwaagijomkNcdZqi7tbLdQdfFPN+Hut0slOU7S7ApoKy+PL4uuoPv22w2XbPZzHWONJ/KcpdYN2n/LmWpeLNWhgBLsCmgLCq8PC46n+cIVWmUpf+7btJ+H7hZKC6CTQFlUeHlcdH5PkeIuzUqq+JK833gZqG4CDYFlEWFt+xFV9cLu67dMFXBzUJxBQk2kp4k6ROSfiDph5JulbSW5tg6BJssKrxlLrq6d1mUof8b8bhZKK7cg42khqTvSPqGpN+QdI2kr0u6V9Ils46vQ7BxbvkKb5mLjsFYlBk3C8UUIthcL+mcpJ88sO8nJD0i6Q2zjq9LsMnCohcdaaZA8c269op2bYYINl+Q9OWY/XdKunPW8QQb/6raPQZkLVSFPqtXoYi9DiGCzfck3Ryz/88lnZ51PMHGvyJ+UbNQtDs9lMc88/QVIWuyiDeMIYLNw5LeFbP/HZIeSThmQ9K2pO21tTW/nwicc9WrmJMmFM1ieQRUW1JQSVpbKY8KfVZX97R5DENd16GCzTtj9neTgs3BjZYNFpF0p1eVVhv8mfbdSTu2mVeZZrVssl70cB5JwWZF/twv6bEx+y8fveZFv99Xq9XSysqKWq2W+v2+r1OhgHZ3dxNf29vbU6fTybE0KJNp3504a2trnkryI91uV41G44J9jUZD3W438XUzG9/Yn1eI735cBMpik3S7pH+K2X+HPCUIVHUMAunNujst84Oo8Cvpu9NsNoPWK/Nmo4X+7itAN9rrNUxzvuLAvpak/5P0B7OOXyTYFHGwDPmatQgc3wUkWWRtpSIKXQ+GCDaXSLpHwwc5r5H0QklflfRdSY+edfwiwaaK06pgfr1eL3ZQl1YuZilTUEkSuocn92AzPKfWJN2i4VQ1D0j6e0mtNMfSsllOFS6aZfEZIAtl/B6FLHOQYLPMxpjN4vgcgGxwLc0vKdjY8LXiWV9fd9vb23Mf1+/31el0tLu7q7W1NXW7XbXbbQ8lLK5Wq6XBYHBofxRF2tnZyb9AQElxLc3PzE4559YP7a9asIG0srKiuL+rmWl/fz9AiYBy4lqaX1Kw8fmcDQJJyv/P47kAoEq4lrJDsKmgWQ+CAUiHayk7BJsKarfb2traUhRFMjNFUaStra1KjF0xQwTyVOVrKW+M2aA0+v2+NjY2tLe3d35fo9Hg4gcKhDEblF6n07kg0EgFmfMJwEwEG5RG0kSJ806gCCB/BBuUBplBQHkRbFAaZAYB5UWwQWmQGYQqqVtmJdloAJCzKmdWko0GqH53kyimOmZWEmxqgkr2R3eTg8FAzjkNBgNtbGzU8rNAWHXMrCTY1ACV7FAd7yZRTHXMrCTY1MAilWwVW0J1vJtEMdUxs5JgUwPzVrJVbQnV8W4SxVTHzEqy0Wpg3gWgqrpgVJUzgICiIButxuZtsvvobipCt1wd7yaBwohbK7oI28mTJ7NaEhtuuJZ6FEXOzFwURVPXUI+i6II118dbFEULn5t13IF6kLTtYup0utFwSNbdTVXtlgNwGN1oSC3r7iaywADQsoF3tGyA+qBlg2Dq+EwBgAsRbOAdWWAA6EYDAGSGbjQAQDAEGwCAdwQbAIB3BBsAgHcEGwCAdwQbAIB3BBuPijDTMYD8ce0fdiR0AapqcjLL8QJkkniYEagwrv14PNTpCfOBAfVU92ufhzpzxkzHQD1x7ccj2HjCevdAPXHtxyPYeMJMx0A9ce3HI9h4wkzHQD1x7cfzkiBgZj8t6XWSniPpCkkPSPqKpBucc19N8x5lTxAAgDrKO0Hg+RoGmr+R9AJJr5V0QtI/m9lJT+cEABSUr+ds/k7SB92BZpOZ3S5pR9L1kl7l6bwAgALyEmycc2di9v3AzP5d0hN9nBMAUFy5JQiY2WMl/bykb+Z1TgBAMeSZjfZnkkzSjUn/wMw2zGzbzLZPnz6dW8EAAH6lCjZm9qtm5lJsdyQc/xZJL5f0u865e5LO45zbcs6tO+fWT5w4sdAvBAAonlSpz2bWkJTm8dc959wFczKY2WskfUjS25xzqZ9qMrPTkg5PMIRpjks6NF4GL/is88NnnY+sPufIOXeoteB1Ik4ze6WG6c/vc8690duJIEkys+24/HZkj886P3zW+fD9OXsbszGzF0n6a0l/SaABgHrzkvpsZr8i6WOSvibpo2b2zAMv/69z7l98nBcAUEy+Hup8rqRHSXq6pC9PvDaQ1PJ03rrbCl2AGuGzzg+fdT68fs6FXTwNAFAdzPoMAPCOYAMA8I5gU3Jm9iQz+4SZ/cDMfmhmt5pZvZcE9MDMXmxmt5jZwMweMrNvm9k7zewxoctWdWb22dFD4+8IXZYqMrOrzexLZvbgqA7ZNrPnZn0egk2JjR62vV3Sz0r6LUmvlPRTkr5oZpeELFsFvVHSOUlvlfTrGj6ovCnpNjPjOvLEzF4m6amhy1FVZnadpE9JOiXpRZJeIunjkhrTjluEr2w05ON3NFyc7mfG0wCZ2dckfUfSdZLeF7BsVfMC59zBCfvuNLPva/jQ8rM1DPrIkJldJun9kn5f0t+GLU31mFlLw7kq3+Scu/HAS5/zcT7uyMrthZLuOjjfnHPuPzRMN78mWKkqaCLQjH1l9JNlM/x4t6S7nXMfC12Qinq1pH1JH87jZASbcvs5Sd+I2X+3pCfnXJY6etboJ8tmZMzMrtRwkcXXhi5LhV0p6VuSXmpm95rZI2Z2j5m9zsfJ6EYrt8dKuj9m//clXZ5zWWrFzJ4o6Y8k/aNzbjt0earEzI5KulnSe51z3w5dngp7wmh7j4ZjkfdqOGbzATM74py7KcuTEWzKL+6pXMu9FDViZo/WcFD1EUnXBi5OFb1Z0sWSUs8Sj4WsSHqMpN92zt062nf7aCznLWb2py7Dp/7pRiu3+zVs3Uy6XPEtHizJzC6S9GkNEzOucs7dF7hIlTJK2+9IukHSo8zsslGigA78/2qwAlbL2dHP2yb2f17S4yQ9PsuTEWzK7W4Nx20mPVnSv+Vclsobde/cIukZkq52zn09cJGq6ApJF0nqaXjDNN6kYfr5/ZKeEqZolXN3wv5xz8h+licj2JTbpyU908yuGO8YNYF/efQaMjJ6lqYv6XmSrnHO3RW4SFX1r5KeE7NJwwD0HEmJq/1iLp8c/bxqYv9Vku5zzn0vy5MxEWeJjR7c/KqkhyS9TcPxmz/WsB/2F5xzDwYsXqWY2YckvUbDcYR/mHj5PrrT/DIzJ6nrnHtb6LJUhZmZpC9o+NBsR9J3Jb1Yw+f3rnXOfTTT8xFsym3Ux/1+Sb+mYfP3C5Je75zbCVmuqjGzHUlRwst/6Jx7e36lqR+CjR9mdqmkd2oYZC7XMBX6Xc65zB+iJdgAALxjzAYA4B3BBgDgHcEGAOAdwQYA4B3BBgDgHcEGAOAdwQYA4B3BBgDg3f8DMgPyoCl2slEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize data\n",
    "plt.plot(data[:,0], data[:,1], 'ko')\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial setup for parameters: `pi`, `mu`, `Sigma` for GMM\n",
    "class Theta(object):\n",
    "    pi = np.empty((0,3))\n",
    "    mu = np.empty((0,3,2))\n",
    "    Sigma = np.empty((0,3,2,2))\n",
    "\n",
    "    def __init__(self, pi, mu, Sigma):\n",
    "        self.pi = pi\n",
    "        self.mu = mu\n",
    "        self.Sigma = Sigma\n",
    "\n",
    "theta_old = Theta(\n",
    "    pi=np.array([0.4, 0.3, 0.3]),\n",
    "    mu=np.array([\n",
    "        [0.0, 0.0],\n",
    "        [3.0, 1.0],\n",
    "        [4.0, 3.0]\n",
    "    ]),\n",
    "    Sigma=np.array([\n",
    "        [[1.0, 0.5],[0.5, 1.0]],\n",
    "        [[1.0, 0.5],[0.5, 1.0]],\n",
    "        [[1.0, 0.5],[0.5, 1.0]]\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Log-Likelihood: 879.0840821295901\n"
     ]
    }
   ],
   "source": [
    "# TODO: implement the objective function, negative log-likelihood, given theta and data x\n",
    "def GMM_objective(theta, x=data):\n",
    "    \"\"\"\n",
    "    `theta`: theta class above\n",
    "    `x`: input data of shape (n,d)\n",
    "    Return the negative log-likelihood of GMM\n",
    "    \"\"\"\n",
    "    # Extract the parameters from theta\n",
    "    num_components = theta.pi.shape[0]\n",
    "    means = theta.mu\n",
    "    covariances = theta.Sigma\n",
    "\n",
    "    log_likelihoods = np.zeros(len(x))\n",
    "    for i in range(len(x)):\n",
    "        likelihoods = np.zeros(num_components)\n",
    "        for j in range(num_components):\n",
    "           likelihoods[j] = theta.pi[j] * multivariate_normal.pdf(x[i], mean=means[j], cov=covariances[j])\n",
    "        log_likelihoods[i] = np.log(np.sum(likelihoods))\n",
    "    \n",
    "    \n",
    "    # Calculate the negative log-likelihood\n",
    "    negative_log_likelihood = -np.sum(log_likelihoods)\n",
    "    return negative_log_likelihood\n",
    "\n",
    "\n",
    "#  testing\n",
    "nll = GMM_objective(theta_old, data)\n",
    "print(\"Negative Log-Likelihood:\", nll)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.3.2: Optimize the Objective Directly (15 points)\n",
    "\n",
    "In this case we ask you to implement a simple __gradient ascent__ algorithm to maximize the log-likelihood function implemented in Exercise 3.3.1.\n",
    "To do that, you need to implement the gradient of the objective, then update using the standard gradient ascent (not descent, since we are maximizing the objective)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMM_objective_grad(theta, x=data):\n",
    "    # TODO: calculate and return the gradient of GMM objective w.r.t `pi`, `mu`, `Sigma`\n",
    "    # Calculate the gradient for each parameter\n",
    "    num_components = theta.pi.shape[0]\n",
    "    means = theta.mu\n",
    "    covariances = theta.Sigma\n",
    "\n",
    "    n, d = x.shape\n",
    "    gradient_pi = np.zeros(num_components)\n",
    "    gradient_mu = np.zeros((num_components, d))\n",
    "    gradient_sigma = np.zeros((num_components, d, d))\n",
    "\n",
    "    log_likelihoods = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        likelihoods = np.zeros(num_components)\n",
    "        for j in range(num_components):\n",
    "            likelihoods[j] = theta.pi[j] * multivariate_normal.pdf(x[i], mean=means[j], cov=covariances[j])\n",
    "        log_likelihoods[i] = np.log(np.sum(likelihoods))\n",
    "\n",
    "        # Calculate the responsibilities\n",
    "        responsibilities = likelihoods / np.sum(likelihoods)\n",
    "\n",
    "        # Compute the gradients for each parameter\n",
    "        gradient_pi += responsibilities\n",
    "        for j in range(num_components):\n",
    "            gradient_mu[j] += responsibilities[j] * (x[i] - means[j])\n",
    "            diff = x[i] - means[j]\n",
    "            gradient_sigma[j] += responsibilities[j] * np.outer(diff, diff)\n",
    "\n",
    "    gradient_pi /= n\n",
    "    gradient_mu /= n\n",
    "    gradient_sigma /= n\n",
    "\n",
    "    # Return the gradients\n",
    "    return gradient_pi, gradient_mu, gradient_sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Parameters:\n",
      "pi: [172.12858695 168.27311969 160.59829335]\n",
      "mu: [[1.45746021 1.92820645]\n",
      " [1.45778033 1.92796766]\n",
      " [1.45753376 1.92809684]]\n",
      "Sigma: [[[ 564.1231568  -319.35989552]\n",
      "  [-319.35989552  811.49678463]]\n",
      "\n",
      " [[ 574.79486016 -314.33847948]\n",
      "  [-314.33847948  765.82501818]]\n",
      "\n",
      " [[ 543.56630247 -301.95687625]\n",
      "  [-301.95687625  740.38987168]]]\n",
      "Objective History: [879.0840821295901, 352.24515915646947, 303.03664632987767, 278.3907678351467, 262.81037952857776, 252.04299205354152, 244.16809938384299, 238.13620955207534, 233.312854395684, 229.30028158881984, 225.87318339302257, 222.9336423549687, 220.4379173519319, 218.3348270810356, 216.55802536330097, 215.0445793850326, 213.74492653694233, 212.6216273102745, 211.64531571636616, 210.7919282480506, 210.04140204154513, 209.37707662160042, 208.78527406428617, 208.25487273337725, 207.7768657270701, 207.3439432785025, 206.9501309839929, 206.59049622718751, 206.26092019135706, 205.9579253314236, 205.67854621388508, 205.42023266738957, 205.18077635317042, 204.95825412480133, 204.75098345529273, 204.5574866557738, 204.37646163649296, 204.2067576600924, 204.047355002181, 203.89734774068486, 203.7559290982695, 203.62237889862456, 203.4960527918725, 203.37637297203764, 203.26282015983605, 203.15492666277945, 203.05227035527162, 202.9544694462291, 202.86117792221106, 202.77208157105366, 202.68689450525034, 202.60535611630795, 202.52722840142275, 202.45229361237384, 202.38035218377266, 202.3112209039487, 202.24473129696307, 202.18072818867128, 202.1190684335247, 202.05961978201168, 202.00225987137728, 201.94687532460043, 201.89336094461106, 201.84161899244148, 201.79155853948237, 201.74309488527655, 201.69614903337379, 201.65064721871192, 201.60652048079683, 201.56370427766183, 201.522138136191, 201.48176533492338, 201.44253261591228, 201.40438992261625, 201.36729016114603, 201.33118898249867, 201.29604458367638, 201.26181752582278, 201.22847056771323, 201.19596851312065, 201.16427807073194, 201.13336772543673, 201.10320761993046, 201.07376944568267, 201.04502634242536, 201.0169528053926, 200.98952459962814, 200.96271868074135, 200.93651312155257, 200.91088704412627, 200.88582055673382, 200.86129469533697, 200.8372913692154, 200.81379331040262, 200.79078402661966, 200.7682477574304, 200.7461694333605, 200.7245346377509, 200.70332957113308, 200.68254101793403, 200.66215631533387, 200.64216332411502, 200.6225504013571, 200.60330637483833, 200.58442051902452, 200.56588253252764, 200.54768251693125, 200.52981095688727, 200.5122587013929, 200.49501694616995, 200.47807721706786, 200.4614313544235, 200.44507149831205, 200.4289900746316, 200.4131797819651, 200.39763357916962, 200.38234467364654, 200.3673065102488, 200.35251276078398, 200.33795731407832, 200.32363426656383, 200.30953791335844, 200.2956627398086, 200.28200341346547, 200.2685547764705, 200.255311838324, 200.24226976901565, 200.22942389249613, 200.2167696804676, 200.20430274647845, 200.19201884030176, 200.1799138425835, 200.1679837597444, 200.1562247191217, 200.14463296433786, 200.1332048508834, 200.12193684190225, 200.11082550416944, 200.09986750425003, 200.08905960483048, 200.07839866121233, 200.06788161796143, 200.05750550570295, 200.04726743805557, 200.03716460869836, 200.02719428856196, 200.01735382313984, 200.007640629912, 199.99805219587677, 199.9885860751845, 199.9792398868692, 199.9700113126723, 199.96089809495473, 199.95189803469367, 199.94300898955817, 199.9342288720628, 199.92555564779195, 199.91698733369603, 199.90852199645147, 199.90015775088582, 199.89189275846218, 199.88372522582168, 199.875653403381, 199.8676755839825, 199.8597901015947, 199.85199533006076, 199.84428968189331, 199.836671607113, 199.82913959212948, 199.8216921586626, 199.81432786270227, 199.8070452935054, 199.79984307262868, 199.79271985299437, 199.78567431799007, 199.7787051805987, 199.77181118255893, 199.76499109355458, 199.75824371043106, 199.75156785643907, 199.74496238050307, 199.7384261565151, 199.73195808265092, 199.72555708071008, 199.71922209547645, 199.7129520941007, 199.7067460655021, 199.70060301979007, 199.69452198770404, 199.68850202007147, 199.6825421872827, 199.6766415787832, 199.67079930258018, 199.6650144847667, 199.6592862690585, 199.6536138163469, 199.64799630426407, 199.6424329267623, 199.6369228937058, 199.63146543047515, 199.62605977758312, 199.62070519030235, 199.61540093830402, 199.61014630530693, 199.60494058873758, 199.5997830993994, 199.594673161152, 199.58961011059998, 199.58459329678988, 199.57962208091715, 199.57469583603947, 199.5698139468006, 199.5649758091602, 199.56018083013183, 199.55542842752848, 199.55071802971514, 199.54604907536782, 199.5414210132394, 199.53683330193218, 199.53228540967643, 199.5277768141148, 199.5233070020927, 199.51887546945437, 199.51448172084432, 199.5101252695139, 199.50580563713353, 199.50152235360918, 199.49727495690414, 199.4930629928653, 199.4888860150541, 199.48474358458145, 199.4806352699475, 199.47656064688465, 199.47251929820604, 199.46851081365588, 199.46453478976568, 199.4605908297122, 199.45667854318043, 199.45279754622916, 199.44894746116026, 199.4451279163909, 199.4413385463293, 199.43757899125313, 199.43384889719124, 199.43014791580802, 199.4264757042906, 199.42283192523902, 199.41921624655848, 199.41562834135476, 199.4120678878322, 199.40853456919282, 199.40502807354002, 199.40154809378237, 199.39809432754106, 199.3946664770591, 199.39126424911223, 199.38788735492247, 199.3845355100736, 199.38120843442803, 199.37790585204638, 199.3746274911081, 199.3713730838344, 199.36814236641297, 199.36493507892385, 199.36175096526765, 199.35858977309474, 199.35545125373662, 199.35233516213816, 199.34924125679214, 199.34616929967424, 199.34311905618029, 199.34009029506447, 199.33708278837935, 199.33409631141606, 199.33113064264722, 199.3281855636701, 199.3252608591515, 199.32235631677324, 199.3194717271795, 199.316606883925, 199.3137615834238, 199.31093562490028, 199.3081288103398, 199.3053409444412, 199.30257183457078, 199.29982129071547, 199.29708912543913, 199.29437515383816, 199.29167919349865, 199.2890010644544, 199.28634058914565, 199.28369759237899, 199.28107190128702, 199.27846334529087, 199.2758717560608, 199.27329696748018, 199.2707388156081, 199.2681971386445, 199.2656717768941, 199.26316257273308, 199.2606693705745, 199.25819201683598, 199.2557303599069, 199.25328425011674, 199.25085353970405, 199.2484380827858, 199.24603773532772, 199.24365235511425, 199.2412818017205, 199.23892593648367, 199.23658462247542, 199.23425772447408, 199.23194510893904, 199.22964664398376, 199.22736219935038, 199.2250916463842, 199.22283485800946, 199.22059170870483, 199.21836207447927, 199.216145832849, 199.2139428628146, 199.21175304483793, 199.20957626082065, 199.20741239408235, 199.2052613293386, 199.20312295268093, 199.20099715155558, 199.1988838147436, 199.196782832341, 199.19469409573898, 199.19261749760543, 199.19055293186548, 199.1885002936832, 199.18645947944398, 199.18443038673576, 199.18241291433245, 199.18040696217616, 199.17841243136064, 199.1764292241143, 199.17445724378427, 199.17249639482026, 199.1705465827587, 199.16860771420727, 199.1666796968297, 199.16476243933104, 199.1628558514424, 199.16095984390716, 199.1590743284663, 199.15719921784452, 199.15533442573658, 199.1534798667939, 199.15163545661093, 199.14980111171258, 199.14797674954085, 199.1461622884425, 199.14435764765668, 199.1425627473026, 199.14077750836765, 199.13900185269526, 199.13723570297364, 199.13547898272435, 199.13373161629056, 199.13199352882657, 199.13026464628672, 199.1285448954146, 199.1268342037325, 199.12513249953125, 199.1234397118598, 199.12175577051522, 199.1200806060329, 199.11841414967688, 199.1167563334301, 199.11510708998503, 199.1134663527345, 199.11183405576259, 199.1102101338355, 199.10859452239276, 199.10698715753864, 199.10538797603354, 199.10379691528533, 199.10221391334142, 199.10063890888026, 199.09907184120348, 199.09751265022803, 199.09596127647805, 199.09441766107756, 199.09288174574255, 199.09135347277368, 199.0898327850491, 199.08831962601707, 199.0868139396887, 199.08531567063122, 199.0838247639606, 199.08234116533535, 199.08086482094956, 199.07939567752612, 199.07793368231017, 199.07647878306327, 199.0750309280564, 199.07359006606418, 199.07215614635817, 199.07072911870188, 199.06930893334356, 199.0678955410112, 199.06648889290653, 199.06508894069913, 199.06369563652095, 199.06230893296075, 199.06092878305907, 199.05955514030182, 199.058187958616, 199.0568271923641, 199.05547279633848, 199.05412472575745, 199.05278293625898, 199.0514473838965, 199.05011802513408, 199.0487948168414, 199.04747771628845, 199.04616668114235, 199.04486166946126, 199.04356263969075, 199.04226955065906, 199.0409823615722, 199.03970103201067, 199.03842552192404, 199.03715579162778, 199.03589180179821, 199.0346335134687, 199.03338088802576, 199.03213388720508, 199.03089247308714, 199.0296566080937, 199.02842625498383, 199.02720137685048, 199.02598193711606, 199.02476789952902, 199.02355922816068, 199.02235588740086, 199.0211578419552, 199.01996505684062, 199.01877749738293, 199.01759512921288, 199.01641791826282, 199.0152458307632, 199.01407883323998, 199.01291689251073, 199.01175997568157, 199.01060805014458, 199.00946108357368, 199.00831904392268, 199.0071818994214, 199.0060496185732, 199.00492217015162, 199.0037995231983, 199.00268164701865, 199.00156851118075, 199.00046008551104, 198.99935634009276, 198.9982572452623, 198.9971627716069, 198.99607288996265, 198.99498757141032, 198.9939067872743, 198.99283050911902, 198.99175870874723, 198.9906913581969, 198.98962842973873, 198.9885698958745, 198.9875157293336, 198.9864659030716, 198.9854203902674, 198.98437916432096, 198.98334219885095, 198.98230946769294, 198.9812809448967, 198.98025660472433, 198.97923642164764, 198.9782203703467, 198.977208425707, 198.97620056281758, 198.9751967569698, 198.97419698365368, 198.97320121855728, 198.97220943756392, 198.97122161675088, 198.9702377323868, 198.96925776092996, 198.96828167902663, 198.9673094635091, 198.9663410913936, 198.96537653987855, 198.96441578634273, 198.96345880834411, 198.9625055836171, 198.9615560900715, 198.96061030579025, 198.95966820902814, 198.9587297782103, 198.95779499193006]\n"
     ]
    }
   ],
   "source": [
    "def GMM_gradient_ascent(theta, n_iters=500, x=data):\n",
    "    \"\"\"\n",
    "    TODO:\n",
    "    Call the above two functions to maximize the objective.\n",
    "    Return the updated parameters and the historical record of objective.\n",
    "    \"\"\"\n",
    "    objective_history = []\n",
    "\n",
    "    for _ in range(n_iters):\n",
    "        objective = GMM_objective(theta, x)\n",
    "        objective_history.append(objective)\n",
    "\n",
    "        gradient_pi, gradient_mu, gradient_sigma = GMM_objective_grad(theta, x)\n",
    "\n",
    "        # Update the parameters using gradient ascent\n",
    "        theta.pi += gradient_pi\n",
    "        theta.mu += gradient_mu\n",
    "        theta.Sigma += gradient_sigma\n",
    "        \n",
    "\n",
    "    return theta, objective_history\n",
    "\n",
    "\n",
    "theta_updated, objective_history = GMM_gradient_ascent(theta_old, n_iters=500, x=data)\n",
    "print(\"Updated Parameters:\")\n",
    "print(\"pi:\", theta_updated.pi)\n",
    "print(\"mu:\", theta_updated.mu)\n",
    "print(\"Sigma:\", theta_updated.Sigma)\n",
    "print(\"Objective History:\", objective_history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.3.3: GMM with EM (20 points)\n",
    "\n",
    "The EM algorithm does not directly deal with the objective function, but instead work on a surrogate. This general line of approach of optimziation for probabilistic models is known as __variational inference__. Now implement the steps of EM algorithm for GMM. Then run the EM algorithm for 500 iterations to obtain the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step(theta, data):\n",
    "    \"\"\"\n",
    "    TODO: implement the E-step of the EM algorithm.\n",
    "    Return the updated `theta`.\n",
    "    \"\"\"\n",
    "    num_components = theta.pi.shape[0]\n",
    "    means = theta.mu\n",
    "    covariances = theta.Sigma\n",
    "\n",
    "    n, d = data.shape\n",
    "    responsibilities = np.zeros((n, num_components))\n",
    "\n",
    "    for i in range(n):\n",
    "        likelihoods = np.zeros(num_components)\n",
    "        for j in range(num_components):\n",
    "            likelihoods[j] = theta.pi[j] * multivariate_normal.pdf(data[i], mean=means[j], cov=covariances[j])\n",
    "        responsibilities[i] = likelihoods / np.sum(likelihoods)\n",
    "\n",
    "    # Update the responsibilities in `theta`\n",
    "    theta.pi = np.mean(responsibilities, axis=0)\n",
    "    theta.mu = np.dot(responsibilities.T, data) / np.sum(responsibilities[:, :, np.newaxis], axis=0)\n",
    "    for j in range(num_components):\n",
    "        diff = data - theta.mu[j]\n",
    "        theta.Sigma[j] = np.einsum('ij,ik->jk', diff, diff * responsibilities[:, j, np.newaxis]) / np.sum(responsibilities[:, j])\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def M_step(theta, data):\n",
    "    \"\"\"\n",
    "    TODO: implement the M-step of the EM algorithm.\n",
    "    Return the updated `theta`.\n",
    "    \"\"\"\n",
    "\n",
    "    n, d = data.shape\n",
    "    num_components = theta.pi.shape[0]\n",
    "    responsibilities = np.zeros((n, num_components))\n",
    "\n",
    "    # Calculate the responsibilities based on the current model parameters\n",
    "    for i in range(n):\n",
    "        likelihoods = np.zeros(num_components)\n",
    "        for j in range(num_components):\n",
    "            likelihoods[j] = theta.pi[j] * multivariate_normal.pdf(data[i], mean=theta.mu[j], cov=theta.Sigma[j])\n",
    "        responsibilities[i] = likelihoods / np.sum(likelihoods)\n",
    "\n",
    "    # Update the model parameters in `theta`\n",
    "    theta.pi = np.mean(responsibilities, axis=0)\n",
    "    theta.mu = np.dot(responsibilities.T, data) / np.sum(responsibilities[:, :, np.newaxis], axis=0)\n",
    "    for j in range(num_components):\n",
    "        diff = data - theta.mu[j]\n",
    "        theta.Sigma[j] = np.einsum('ij,ik->jk', diff, diff * responsibilities[:, j, np.newaxis]) / np.sum(responsibilities[:, j])\n",
    "\n",
    "    return theta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Parameters:\n",
      "pi: [0.30070365 0.17993715 0.5193592 ]\n",
      "mu: [[0.0213607  4.94776653]\n",
      " [4.94239198 0.31365344]\n",
      " [1.08181039 0.7390666 ]]\n",
      "Sigma: [[[ 0.29324532  0.05052346]\n",
      "  [ 0.05052346  0.35275804]]\n",
      "\n",
      " [[ 0.35564413 -0.01494922]\n",
      "  [-0.01494922  0.66695052]]\n",
      "\n",
      " [[ 0.67114087  0.33058391]\n",
      "  [ 0.33058391  0.90436499]]]\n",
      "Objective History: [198.95686382894738, 408.3374444458874, 408.3374131147494, 408.33698977749225, 408.3312817184606, 408.25565615008173, 407.32225881858386, 398.2712650307274, 372.10306223198205, 366.84327780419255, 365.92679772681805, 365.15066038151855, 364.2905914184436, 363.59360129430263, 363.1610195148636, 362.84348453664836, 362.4646599092135, 361.74099427172143, 359.2938074899439, 345.42720336685113, 334.77264880695435, 332.3652785103112, 330.9870668557376, 330.05402553554734, 328.879892288072, 326.46480792405276, 321.9328787570448, 318.88550023596036, 318.83082399236434, 318.8308208542671, 318.8308208519539, 318.8308208519414, 318.83082085194127, 318.8308208519412, 318.83082085194127, 318.8308208519413, 318.83082085194127, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413, 318.8308208519413]\n"
     ]
    }
   ],
   "source": [
    "def EM(theta, data, n_iter=500):\n",
    "    \"\"\"\n",
    "    TODO: implement the EM algorithm.\n",
    "    Be sure to call the above two functions `E_step` and `M_step`.\n",
    "    `theta` is the `Theta` class above; `data` is the `data` above.\n",
    "    Return the updated `theta` values and the historical record of objective.\n",
    "    \"\"\"\n",
    "    objective_history = []\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        objective = GMM_objective(theta, data)\n",
    "        objective_history.append(objective)\n",
    "\n",
    "        # E-step\n",
    "        theta = E_step(theta, data)\n",
    "\n",
    "        # M-step\n",
    "        theta = M_step(theta, data)\n",
    "\n",
    "    return theta, objective_history\n",
    "\n",
    "\n",
    "theta_updated, objective_history = EM(theta_old, data, n_iter=500)\n",
    "print(\"Updated Parameters:\")\n",
    "print(\"pi:\", theta_updated.pi)\n",
    "print(\"mu:\", theta_updated.mu)\n",
    "print(\"Sigma:\", theta_updated.Sigma)\n",
    "print(\"Objective History:\", objective_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def GMM_objective_grad(theta, x):\n",
    "    \"\"\"\n",
    "    Calculate and return the gradient of GMM objective w.r.t `pi`, `mu`, `Sigma`.\n",
    "    `theta`: Theta class with GMM parameters.\n",
    "    `x`: Input data of shape (n, d).\n",
    "    \"\"\"\n",
    "    num_components = theta.pi.shape[0]\n",
    "    means = theta.mu\n",
    "    covariances = theta.Sigma\n",
    "\n",
    "    n, d = x.shape\n",
    "    gradient_pi = np.zeros(num_components)\n",
    "    gradient_mu = np.zeros((num_components, d))\n",
    "    gradient_sigma = np.zeros((num_components, d, d))\n",
    "\n",
    "    for i in range(n):\n",
    "        likelihoods = np.zeros(num_components)\n",
    "        for j in range(num_components):\n",
    "            likelihoods[j] = theta.pi[j] * multivariate_normal.pdf(x[i], mean=means[j], cov=covariances[j])\n",
    "        likelihoods_sum = np.sum(likelihoods)\n",
    "\n",
    "        # Calculate the responsibilities\n",
    "        responsibilities = likelihoods / likelihoods_sum\n",
    "\n",
    "        # Compute the gradients for each parameter\n",
    "        gradient_pi += responsibilities\n",
    "        for j in range(num_components):\n",
    "            gradient_mu[j] += responsibilities[j] * (x[i] - means[j])\n",
    "            diff = x[i] - means[j]\n",
    "            gradient_sigma[j] += responsibilities[j] * np.outer(diff, diff)\n",
    "\n",
    "    gradient_pi /= n\n",
    "    gradient_mu /= n\n",
    "    gradient_sigma /= n\n",
    "\n",
    "    # Return the gradients\n",
    "    return gradient_pi, gradient_mu, gradient_sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.3.4 (10 points)\n",
    "\n",
    "Based on the saved intermediate values of log-likelihood for the values above, plot and observe the behavior of log-likelihood in each case.\n",
    "Summarize your observations. This execrise is open-ended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Plot the intermediate values of log-likelihood in each case\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_log_likelihood(objective_history):\n",
    "    \"\"\"\n",
    "    Plot the intermediate values of log-likelihood.\n",
    "    \"\"\"\n",
    "    plt.plot(objective_history)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Log-Likelihood')\n",
    "    plt.title('Behavior of Log-Likelihood')\n",
    "    plt.show()\n",
    "\n",
    "theta_updated, objective_history = EM(theta_old, data, n_iter=500)\n",
    "# print(objective_history)\n",
    "plot_log_likelihood(objective_history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TODO: Write your answer here]**\n",
    "\n",
    "The EM algorithm is not converging or updating the parameters correctly.\n",
    "\n",
    "There could be several reasons why this is happening:\n",
    "\n",
    "Initialization: The initial parameters (theta_old) may not be appropriate for the given data. Initializing the parameters close to the true values or using a different initialization strategy (e.g., random initialization) might help.\n",
    "\n",
    "Implementation: There might be errors in the implementation of the E-step or M-step of the EM algorithm. It's important to double-check the calculations for updating the parameters and ensure they are implemented correctly.\n",
    "\n",
    "Data-related issues: The data itself may pose challenges for the EM algorithm. For example, if the data points are poorly distributed or the clusters are highly overlapping, it can make convergence difficult.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy as np\\nimport scipy.stats as stats\\n\\nclass Theta:\\n    def __init__(self, pi, mu, Sigma):\\n        self.pi = pi\\n        self.mu = mu\\n        self.Sigma = Sigma\\n\\ndef compute_log_likelihood1(theta, data):\\n    log_likelihood = 0.0\\n    for x in data:\\n        prob = 0.0\\n        for k in range(len(theta.pi)):\\n            prob += theta.pi[k] * stats.multivariate_normal.pdf(x, theta.mu[k], theta.Sigma[k])\\n        log_likelihood += np.log(prob)\\n    return log_likelihood\\n\\ndef E_step1(theta, data):\\n    # Compute responsibilities\\n    responsibilities = np.zeros((len(data), len(theta.pi)))\\n    for i, x in enumerate(data):\\n        for k in range(len(theta.pi)):\\n            responsibilities[i, k] = theta.pi[k] * stats.multivariate_normal.pdf(x, theta.mu[k], theta.Sigma[k])\\n        responsibilities[i] /= np.sum(responsibilities[i])\\n    return responsibilities\\n\\ndef M_step1(theta, data, responsibilities):\\n    # Update parameters\\n    N_k = np.sum(responsibilities, axis=0)\\n    \\n    new_pi = N_k / len(data)\\n    \\n    new_mu = np.zeros_like(theta.mu)\\n    for k in range(len(theta.pi)):\\n        for i, x in enumerate(data):\\n            new_mu[k] += responsibilities[i, k] * x\\n        new_mu[k] /= N_k[k]\\n    \\n    new_Sigma = np.zeros_like(theta.Sigma)\\n    for k in range(len(theta.pi)):\\n        for i, x in enumerate(data):\\n            diff = x - new_mu[k]\\n            new_Sigma[k] += responsibilities[i, k] * np.outer(diff, diff)\\n        new_Sigma[k] /= N_k[k]\\n\\n    return Theta(new_pi, new_mu, new_Sigma)\\n\\ndef EM_test(theta_old, data, n_iters):\\n    objective_history = []\\n    theta_updated = theta_old\\n    for i in range(n_iters):\\n        # E-step\\n        responsibilities = E_step1(theta_updated, data)\\n\\n        # M-step\\n        theta_updated = M_step1(theta_updated, data, responsibilities)\\n\\n        # Compute log-likelihood\\n        log_likelihood = compute_log_likelihood1(theta_updated, data)\\n        objective_history.append(log_likelihood)\\n\\n    return theta_updated, objective_history\\n\\n# testing\\ntheta_updated, objective_history = EM_test(theta_old, data, n_iters=500)\\nprint(\"Final parameters:\")\\nprint(\"pi:\", theta_updated.pi)\\nprint(\"mu:\", theta_updated.mu)\\nprint(\"Sigma:\", theta_updated.Sigma)\\nprint(\"Objective history:\", objective_history)\\n'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implementated by scipy for testing\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "class Theta:\n",
    "    def __init__(self, pi, mu, Sigma):\n",
    "        self.pi = pi\n",
    "        self.mu = mu\n",
    "        self.Sigma = Sigma\n",
    "\n",
    "def compute_log_likelihood1(theta, data):\n",
    "    log_likelihood = 0.0\n",
    "    for x in data:\n",
    "        prob = 0.0\n",
    "        for k in range(len(theta.pi)):\n",
    "            prob += theta.pi[k] * stats.multivariate_normal.pdf(x, theta.mu[k], theta.Sigma[k])\n",
    "        log_likelihood += np.log(prob)\n",
    "    return log_likelihood\n",
    "\n",
    "def E_step1(theta, data):\n",
    "    # Compute responsibilities\n",
    "    responsibilities = np.zeros((len(data), len(theta.pi)))\n",
    "    for i, x in enumerate(data):\n",
    "        for k in range(len(theta.pi)):\n",
    "            responsibilities[i, k] = theta.pi[k] * stats.multivariate_normal.pdf(x, theta.mu[k], theta.Sigma[k])\n",
    "        responsibilities[i] /= np.sum(responsibilities[i])\n",
    "    return responsibilities\n",
    "\n",
    "def M_step1(theta, data, responsibilities):\n",
    "    # Update parameters\n",
    "    N_k = np.sum(responsibilities, axis=0)\n",
    "    \n",
    "    new_pi = N_k / len(data)\n",
    "    \n",
    "    new_mu = np.zeros_like(theta.mu)\n",
    "    for k in range(len(theta.pi)):\n",
    "        for i, x in enumerate(data):\n",
    "            new_mu[k] += responsibilities[i, k] * x\n",
    "        new_mu[k] /= N_k[k]\n",
    "    \n",
    "    new_Sigma = np.zeros_like(theta.Sigma)\n",
    "    for k in range(len(theta.pi)):\n",
    "        for i, x in enumerate(data):\n",
    "            diff = x - new_mu[k]\n",
    "            new_Sigma[k] += responsibilities[i, k] * np.outer(diff, diff)\n",
    "        new_Sigma[k] /= N_k[k]\n",
    "\n",
    "    return Theta(new_pi, new_mu, new_Sigma)\n",
    "\n",
    "def EM_test(theta_old, data, n_iters):\n",
    "    objective_history = []\n",
    "    theta_updated = theta_old\n",
    "    for i in range(n_iters):\n",
    "        # E-step\n",
    "        responsibilities = E_step1(theta_updated, data)\n",
    "\n",
    "        # M-step\n",
    "        theta_updated = M_step1(theta_updated, data, responsibilities)\n",
    "\n",
    "        # Compute log-likelihood\n",
    "        log_likelihood = compute_log_likelihood1(theta_updated, data)\n",
    "        objective_history.append(log_likelihood)\n",
    "\n",
    "    return theta_updated, objective_history\n",
    "\n",
    "# testing\n",
    "theta_updated, objective_history = EM_test(theta_old, data, n_iters=500)\n",
    "print(\"Final parameters:\")\n",
    "print(\"pi:\", theta_updated.pi)\n",
    "print(\"mu:\", theta_updated.mu)\n",
    "print(\"Sigma:\", theta_updated.Sigma)\n",
    "print(\"Objective history:\", objective_history)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
